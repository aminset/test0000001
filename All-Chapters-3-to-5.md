# Chapter 3 – Processes (فصل ۳: فرایندها)

## **اسلاید 1 – عنوان: Chapter 3: Processes**
**ترجمه:**
سیستم‌عامل‌های پیشرفته (Advanced Operating Systems) — فصل ۳: فرایندها (Processes).
**جزوه:**

* این فصل درباره‌ی «فرایند (Process)»، «نخ (Thread)»، کلاینت/سرور چندنخی و «مهاجرت کُد (Code Migration)» است.
  **تعاریف/توضیحات کوتاه:**
* فرایند (Process): برنامه در حال اجرا + منابع و وضعیت اجرا.
  **Key Points:**
* تمرکز فصل: Threads، Multithreaded Client/Server، Code Migration
* هدف: سادگی طراحی سیستم توزیع‌شده + افزایش کارایی

---

## **اسلاید 2 – عنوان: Contents**
**ترجمه:**
فهرست:

* نخ‌ها (Threads)
* کلاینت‌های چندنخی (Multithreaded Clients)
* سرورهای چندنخی (Multithreaded Servers)
* مهاجرت کُد (Code Migration)
  **جزوه:**
* ساختار فصل: ابتدا مفهوم نخ‌ها → بعد کاربرد در کلاینت/سرور → سپس مهاجرت کُد.
  **تعاریف/توضیحات کوتاه:**
* چندنخی (Multithreaded): داشتن چند مسیر اجرای هم‌زمان در یک برنامه/فرایند.
  **Key Points:**
* 4 بخش اصلی فصل مشخص است
* نخ‌ها پایه‌ی کلاینت/سرور چندنخی هستند

---

## **اسلاید 3 – عنوان: THREADS**
**ترجمه:**
یک فرایند (Process) معمولاً به‌صورت «یک برنامه در حال اجرا» تعریف می‌شود.
داشتن نوعی **چند مسیر کنترل/چند نخ کنترل (multiple threads of control)** در هر فرایند، ساخت برنامه‌های توزیع‌شده را بسیار ساده‌تر می‌کند و کمک می‌کند به کارایی (Performance) بهتر برسیم.
نخ‌ها (Threads) اغلب به‌صورت یک **بسته‌ی نخ (Thread Package)** ارائه می‌شوند. این بسته عملیات ایجاد و نابودی نخ‌ها را فراهم می‌کند و همچنین عملیات مربوط به متغیرهای همگام‌سازی (Synchronization Variables) مثل **متغیرهای شرطی (Condition Variables)** را دارد.
در کل دو رویکرد اصلی برای پیاده‌سازی بسته‌ی نخ وجود دارد…
**جزوه:**

* چرا نخ؟

  * افزایش هم‌زمانی (Concurrency) و پاسخ‌گویی
  * ساده‌تر شدن طراحی سرویس‌های توزیع‌شده
* Thread Package معمولاً شامل:

  * Create/Destroy Thread
  * Synchronization: Mutex/Condition Variable
* 2 رویکرد پیاده‌سازی Thread Package:

  * نخ‌های سطح کاربر (ULT)
  * نخ‌های سطح هسته (KLT)
    **تعاریف/توضیحات کوتاه:**
* متغیر شرطی (Condition Variable): ابزاری برای «منتظر ماندن تا یک شرط برقرار شود» همراه با mutex.
  **Key Points:**
* Process = برنامه در حال اجرا
* Thread = مسیر اجرای سبک‌تر داخل Process
* Thread Package عملیات نخ + همگام‌سازی را می‌دهد

---

## **اسلاید 4 – عنوان: ULTs (User Level Threads)**
**ترجمه:**
**نخ‌های سطح کاربر (User-Level Threads)** در فضای کاربر (User Space) مدیریت می‌شوند.
**مزیت‌ها:**

* ایجاد و حذف نخ‌ها ارزان (Cheap) است.
  …
  **عیب‌ها:**
* (به‌صورت کلی) اگر فراخوانی سیستم (System Call) بلوکه‌کننده باشد یا عملیات I/O بلوکه شود، ممکن است کل فرایند گرفتار توقف شود، چون هسته از نخ‌های سطح کاربر خبر ندارد.
  **جزوه:**
* ULT = مدیریت نخ‌ها در User Space (بدون دخالت مستقیم کرنل)
* مزیت کلیدی: سرعت و هزینه‌ی کم برای عملیات نخ
* ضعف رایج: کرنل نخ‌ها را نمی‌بیند ⇒ بلوکه شدن یک نخ می‌تواند اجرای فرایند را مختل کند
  **تعاریف/توضیحات کوتاه:**
* User Space: بخشی که برنامه‌ها اجرا می‌شوند و مستقیم به هسته دسترسی ندارند.
  **Key Points:**
* ULT سریع و کم‌هزینه است
* مشکل اصلی: تعامل با system call/I/O بلوکه‌کننده

---

## **اسلاید 5 – عنوان: KLTs (Kernel Level Threads)**
**ترجمه:**
در **نخ‌های سطح هسته (Kernel-Level Threads)** تمام مدیریت نخ‌ها داخل فضای آدرس هسته (Kernel Address Space) انجام می‌شود.
**مزیت‌ها:**

* اجرای یک system call بلوکه‌کننده باعث نمی‌شود کل برنامه مثل حالت ULT قفل شود (به‌طور کلی سیستم بهتر می‌تواند زمان‌بندی کند).
  **عیب‌ها:**
* هزینه بالا: هر عملیات نخ (ایجاد، حذف، همگام‌سازی و …) باید توسط هسته انجام شود و نیاز به **فراخوانی سیستم (System Call)** دارد.
* تعویض زمینه‌ی نخ‌ها (Thread Context Switch) می‌تواند تقریباً به گرانی تعویض زمینه‌ی فرایندها (Process Context Switch) شود.
  **جزوه:**
* KLT = نخ‌ها توسط کرنل شناخته می‌شوند و کرنل زمان‌بندی می‌کند
* مزیت مهم: مدیریت بهتر بلوکه‌شدن‌ها و استفاده بهتر از CPU
* هزینه مهم: هر کار نخ ⇒ system call ⇒ سربار زیاد
  **تعاریف/توضیحات کوتاه:**
* Context Switch: جابه‌جایی CPU بین دو واحد اجرا (نخ/فرایند) با ذخیره/بازیابی وضعیت.
  **Key Points:**
* KLT انعطاف و کنترل کرنل را دارد
* عیب اصلی: سربار system call و context switch گران

---

## **اسلاید 6 – عنوان: Lightweight Processes (LWP) – hybrid**
**ترجمه:**
یک شکل ترکیبی از نخ‌های سطح کاربر و سطح هسته وجود دارد: **فرایندهای سبک (Lightweight Processes یا LWP)**.
یک LWP در بستر یک فرایند (Heavy-weight Process) اجرا می‌شود و می‌تواند چندین LWP در هر فرایند وجود داشته باشد.
علاوه بر LWPها، سیستم یک بسته‌ی نخ سطح کاربر هم می‌دهد تا عملیات ایجاد/حذف نخ را ارائه کند. همچنین امکانات همگام‌سازی نخ مثل متغیر شرطی را می‌دهد.
نکته‌ی مهم: بسته‌ی نخ کاملاً در فضای کاربر پیاده‌سازی می‌شود؛ یعنی عملیات نخ‌ها بدون دخالت هسته انجام می‌شود.
**جزوه:**

* هدف LWP: گرفتن مزیت ULT (ارزان بودن) + حل مشکل بلوکه‌شدن با کمک موجودیت‌های سطح هسته
* مدل:

  * LWPها در سطح هسته/سیستم وجود دارند (مثل “کانال اجرای قابل زمان‌بندی”)
  * نخ‌های واقعی برنامه در User Space مدیریت می‌شوند
    **تعاریف/توضیحات کوتاه:**
* LWP: واسطه‌ای بین ULT و کرنل؛ مثل «هسته‌ی زمان‌بندی‌پذیر» برای اجرای نخ‌های سطح کاربر.
  **Key Points:**
* LWP مدل hybrid است
* Thread package در user space می‌ماند
* هدف: ارزان بودن + جلوگیری از گیرکردن کل فرایند

---

## **اسلاید 7 – عنوان: lightweight processes (LWP) (continue)**
**ترجمه:**
هر LWP می‌تواند نخِ سطح کاربر خودش را اجرا کند.
برنامه‌های چندنخی با ایجاد نخ‌ها ساخته می‌شوند و سپس هر نخ به یک LWP نسبت داده می‌شود. این نسبت‌دادن معمولاً ضمنی است و از برنامه‌نویس پنهان می‌ماند.
هنگام ایجاد LWP (با system call)، LWP پشته‌ی خودش را می‌گیرد و مامور می‌شود روتین زمان‌بندی (Scheduling Routine) را اجرا کند تا یک نخِ قابل اجرا پیدا کند.
اگر چند LWP وجود داشته باشد، هر کدام زمان‌بند را اجرا می‌کنند. جدول نخ‌ها (Thread Table) بین LWPها مشترک است و حفاظت از دسترسی انحصاری به آن با **mutex**هایی انجام می‌شود که کاملاً در فضای کاربر پیاده‌سازی شده‌اند.
**جزوه:**

* LWPها “runner” هستند، نخ‌های user-level “کارها” هستند
* Scheduling در user space انجام می‌شود
* Thread Table مشترک ⇒ نیاز به Mutex برای دسترسی انحصاری
  **تعاریف/توضیحات کوتاه:**
* Mutex (Mutual Exclusion): قفل برای جلوگیری از ورود هم‌زمان چند نخ به بخش بحرانی.
  **Key Points:**
* هر LWP stack خودش را دارد
* زمان‌بندی و mutex در user space
* Thread Table بین LWPها مشترک است

---

## **اسلاید 8 – عنوان: lightweight processes (LWP) (continue)**
**ترجمه:**
به عبارت دیگر، همگام‌سازی بین LWPها به پشتیبانی هسته نیاز ندارد.
وقتی یک LWP یک نخِ قابل اجرا پیدا می‌کند، به آن نخ **context switch** می‌زند. در همین زمان، LWPهای دیگر هم ممکن است دنبال نخ‌های قابل اجرا بگردند.
اگر یک نخ لازم باشد روی یک mutex یا condition variable بلوکه شود، کارهای مدیریتی لازم را انجام می‌دهد و سپس روتین زمان‌بندی را صدا می‌زند.
وقتی نخ قابل اجرای دیگری پیدا شد، به آن نخ context switch انجام می‌شود.
مزیت زیبای این روش: LWPای که نخ را اجرا می‌کند لازم نیست مطلع شود؛ چون context switch کاملاً در user space پیاده‌سازی می‌شود و برای LWP مثل اجرای عادی کد برنامه به نظر می‌رسد.
**جزوه:**

* بلاک/آزاد شدن نخ‌ها بدون دخالت کرنل (تا جای ممکن)
* context switch بین نخ‌های user-level در user space
  **تعاریف/توضیحات کوتاه:**
* Runnable Thread: نخ آماده اجرا (نه بلوکه، نه پایان‌یافته).
  **Key Points:**
* Sync و context switch در user space
* بلاک روی mutex/condition ⇒ برگشت به scheduler
* LWP “خبر ندارد”، فقط کد اجرا می‌شود

---

## **اسلاید 9 – عنوان: Advantages of LWP + ULT**
**ترجمه:**
مزیت‌های استفاده از LWPها همراه با بسته نخ سطح کاربر:

1. ایجاد، حذف و همگام‌سازی نخ‌ها ارزان است و هیچ دخالت هسته‌ای ندارد.
2. اگر فرایند LWP کافی داشته باشد، یک system call بلوکه‌کننده کل فرایند را متوقف نمی‌کند.
3. برنامه نیازی ندارد درباره LWP بداند؛ فقط نخ‌های سطح کاربر را می‌بیند.
4. LWPها در محیط چندپردازنده به‌راحتی روی CPUهای مختلف اجرا می‌شوند و این چندپردازشی می‌تواند از برنامه پنهان بماند.
   تنها عیب: هنوز باید LWPها را ایجاد/حذف کرد که هزینه‌اش مثل نخ سطح هسته بالاست؛ اما این کار معمولاً گاهی انجام می‌شود و اغلب تحت کنترل سیستم‌عامل است.
   **جزوه:**

* جمع‌بندی hybrid:

  * نخ‌ها ارزان (مثل ULT)
  * بلوکه شدن مدیریت‌پذیر (با داشتن LWP کافی)
  * پشتیبانی مناسب از چندپردازنده
* عیب: LWP همچنان موجودیت نسبتاً سنگین‌تری است
  **تعاریف/توضیحات کوتاه:**
* Multiprocessing: اجرای هم‌زمان روی چند CPU/Core.
  **Key Points:**
* Cheap thread ops
* Blocking call ≠ توقف کل process (با LWP کافی)
* عیب اصلی: هزینه ایجاد/حذف LWP

---

## **اسلاید 10 – عنوان: Multithreaded Clients**
**ترجمه:**
برای رسیدن به شفافیت توزیع‌شده (Distribution Transparency) بالا، یک سند وب معمولاً شامل یک فایل HTML (متن ساده) به همراه مجموعه‌ای از تصاویر، آیکون‌ها و… است.
برای دریافت هر جزء سند وب، مرورگر باید یک اتصال TCP/IP برقرار کند، داده‌ها را بخواند و به بخش نمایش بدهد. برقرار کردن اتصال و خواندن داده‌ها ذاتاً عملیات بلوکه‌کننده هستند.
توسعه مرورگر به‌صورت یک کلاینت چندنخی (Multithreaded Client) کار را خیلی ساده‌تر می‌کند.
**جزوه:**

* مشکل: Fetch کردن اجزای متعدد وب ⇒ اتصال‌ها و خواندن‌ها بلوکه‌کننده
* راه‌حل: چند نخ برای دانلود هم‌زمان اجزا
  **تعاریف/توضیحات کوتاه:**
* Distribution Transparency: کاربر حس کند سیستم یکپارچه است، نه مجموعه‌ای از ماشین‌های جدا.
  **Key Points:**
* وب‌پیج = HTML + منابع متعدد
* TCP connect/read بلوکه‌کننده
* Multithreading ⇒ ساده‌سازی + سرعت

---

## **اسلاید 11 – عنوان: Multithreaded Clients (continue)**
**ترجمه:**
به‌محض اینکه فایل اصلی HTML دریافت شد، نخ‌های جداگانه فعال می‌شوند تا بقیه بخش‌ها را دریافت کنند.
هر نخ یک اتصال جدا به سرور می‌سازد و داده را می‌کشد (Pull). اتصال‌سازی و خواندن داده می‌تواند با کتابخانه‌های استاندارد برنامه‌نویسی انجام شود.
…
**جزوه:**

* الگو: Main thread ⇒ HTML اصلی
* Worker threads ⇒ تصاویر/آیکون‌ها/… با اتصال‌های جدا
  **تعاریف/توضیحات کوتاه:**
* Pull data: کلاینت فعالانه داده را دریافت می‌کند (درخواست می‌دهد و می‌خواند).
  **Key Points:**
* بعد از HTML اصلی، دانلود موازی منابع
* هر نخ یک connection مستقل

---

## **اسلاید 12 – عنوان: Multithreaded Clients (continue)**
**ترجمه:**
فایده مهم دیگر مرورگر چندنخی این است که چند اتصال می‌تواند هم‌زمان باز باشد.
در مثال قبل، چند اتصال به همان سرور برقرار شد. اگر آن سرور خیلی شلوغ یا کند باشد…
راه‌حل: سرورهای وب روی چند ماشین **تکثیر (Replicate)** می‌شوند، طوری که هر سرور دقیقاً همان مجموعه اسناد وب را ارائه می‌دهد.
**جزوه:**

* مشکل bottleneck: یک سرور کند/پر بار
* راهکار: Replication (چند نسخه از سرور)
  **تعاریف/توضیحات کوتاه:**
* Replication: داشتن چند کپی همسان برای افزایش ظرفیت/دسترس‌پذیری.
  **Key Points:**
* اتصال‌های هم‌زمان کمک می‌کنند
* Replicated servers برای کاهش فشار/افزایش سرعت

---

## **اسلاید 13 – عنوان: Multithreaded Clients (continue)**
**ترجمه:**
سرورهای تکثیرشده در یک سایت قرار دارند و با یک نام شناخته می‌شوند.
وقتی درخواست صفحه وب می‌آید، درخواست به یکی از سرورها هدایت می‌شود (مثلاً با روش round-robin یا روش‌های توازن بار).
در کلاینت چندنخی، اتصال‌ها می‌توانند به replicaهای مختلف زده شوند و داده‌ها موازی منتقل شود؛ در نتیجه کل سند وب خیلی سریع‌تر از حالتی که فقط یک سرور (بدون replication) باشد نمایش داده می‌شود.
**جزوه:**

* Load balancing: توزیع درخواست بین replicaها
* Multithreaded client + replicated server ⇒ دانلود موازی واقعی
  **تعاریف/توضیحات کوتاه:**
* Round-robin: تقسیم نوبتی درخواست‌ها بین سرورها.
  **Key Points:**
* Replicas تحت یک نام
* Load balancing
* Parallel transfer ⇒ زمان نمایش کمتر

---

## **اسلاید 14 – عنوان: Multithreaded Servers**
**ترجمه:**
سازمان‌دهی یک فایل‌سرور را در نظر بگیرید که گاهی مجبور است برای دیسک منتظر بماند (block).
فایل‌سرور معمولاً منتظر درخواست عملیات فایل می‌ماند، سپس درخواست را انجام می‌دهد و پاسخ می‌فرستد.
در اینجا یک نخ به نام **dispatcher** درخواست‌های ورودی عملیات فایل را می‌خواند. درخواست‌ها به یک نقطه پایانی شناخته‌شده (well-known end point) ارسال می‌شوند.
بعد از بررسی درخواست، سرور یک نخ worker بیکار (یعنی بلوکه/منتظر) را انتخاب می‌کند و درخواست را به آن می‌دهد.
**جزوه:**

* مدل Dispatcher/Worker برای سرورهای چندنخی
* Dispatcher: دریافت و توزیع درخواست‌ها
* Worker: انجام عملیات (ممکن است روی دیسک block شود)
  **تعاریف/توضیحات کوتاه:**
* Well-known endpoint: آدرس/پورت ثابتی که همه کلاینت‌ها می‌دانند.
  **Key Points:**
* سرور ممکن است روی disk I/O بلوکه شود
* Dispatcher درخواست‌ها را پخش می‌کند
* Workerها عملیات را انجام می‌دهند

---

## **اسلاید 15 – عنوان: Multithreaded Servers**
**ترجمه:**
worker با انجام یک read بلوکه‌کننده روی فایل‌سیستم محلی پیش می‌رود و ممکن است نخ تا زمانی که داده از دیسک بیاید suspend شود.
اگر نخ suspend شود، نخ دیگری برای اجرا انتخاب می‌شود.
(شکل) سرور چندنخی در مدل dispatcher/worker.
**جزوه:**

* چرا این مدل خوب است؟

  * وقتی یک worker روی دیسک گیر می‌کند، workerهای دیگر ادامه می‌دهند
  * استفاده بهتر از CPU و پاسخ‌گویی بهتر
    **تعاریف/توضیحات کوتاه:**
* Blocking read: خواندن که تا آماده شدن داده متوقف می‌ماند.
  **Key Points:**
* Worker ممکن است suspend شود
* زمان‌بند نخ دیگر را اجرا می‌کند
* افزایش throughput سرور

---

## **اسلاید 16 – عنوان: CODE MIGRATION**
**ترجمه:**
به‌صورت سنتی، مهاجرت کُد (Code Migration) در سیستم‌های توزیع‌شده به شکل **مهاجرت فرایند (Process Migration)** انجام می‌شد؛ یعنی کل یک فرایند از یک ماشین به ماشین دیگر منتقل می‌شد.
دلایل مهاجرت کُد:

* کارایی (Performance)
* انعطاف‌پذیری (Flexibility)
  **جزوه:**
* Code/Process Migration: انتقال اجرای برنامه یا بخشی از آن به ماشین دیگر
* دو انگیزه اصلی:

  * بهبود performance
  * پیکربندی پویا و انعطاف
    **تعاریف/توضیحات کوتاه:**
* Process Migration: انتقال کل process (کُد + وضعیت اجرا + منابع مرتبط).
  **Key Points:**
* مدل کلاسیک: جابه‌جایی کل process
* اهداف: Performance و Flexibility

---

## **اسلاید 17 – عنوان: Reasons for Migrating Code / Performance**
**ترجمه:**
ایده اصلی: کارایی کلی سیستم بهتر می‌شود اگر فرایندها از ماشین‌های پر‌بار به ماشین‌های کم‌بار منتقل شوند.
بار معمولاً با طول صف CPU یا میزان استفاده CPU بیان می‌شود.
یک سیستم کلاینت-سرور را در نظر بگیرید که سرور یک پایگاه‌داده عظیم را مدیریت می‌کند. اگر کلاینت نیاز به عملیات زیاد پایگاه‌داده با حجم داده بزرگ داشته باشد، بهتر است بخشی از برنامه کلاینت را به سرور بفرستیم و فقط نتایج را از شبکه عبور دهیم.
اینجا فرض این است که معمولاً منطقی است داده را نزدیک محل قرارگیری‌اش پردازش کنیم.
**جزوه:**

* Load balancing با migration
* اصل مهم: **Move computation to data** (پردازش نزدیک داده)
* کاهش ترافیک شبکه: ارسال نتیجه به جای ارسال حجم زیاد داده خام
  **تعاریف/توضیحات کوتاه:**
* CPU queue length: تعداد کارهای منتظر CPU.
  **Key Points:**
* مهاجرت از heavy-load به light-load
* پردازش نزدیک داده
* کاهش هزینه شبکه

---

## **اسلاید 18 – عنوان: Reasons for Migrating Code / Performance**
**ترجمه:**
همین دلیل می‌تواند برای مهاجرت بخشی از سرور به سمت کلاینت هم استفاده شود.
در بسیاری از برنامه‌های تعاملی پایگاه‌داده، کلاینت باید فرم‌هایی را پر کند که بعداً به مجموعه‌ای از عملیات پایگاه‌داده تبدیل می‌شوند.
اگر پردازش فرم در سمت کلاینت انجام شود و فقط فرم تکمیل‌شده به سرور ارسال شود، گاهی از عبور تعداد زیادی پیام کوچک از شبکه جلوگیری می‌شود.
نتیجه: کلاینت کارایی/سرعت بهتری حس می‌کند و هم‌زمان سرور زمان کمتری صرف پردازش فرم و ارتباطات می‌کند.
**جزوه:**

* انتقال بخشی از منطق به client برای کاهش پیام‌های ریز (chatty communication)
* بهبود perceived performance برای کاربر
  **تعاریف/توضیحات کوتاه:**
* Chatty protocol: پروتکلی که تعداد زیادی پیام کوچک رد و بدل می‌کند.
  **Key Points:**
* گاهی computation را به client می‌بریم
* کاهش تعداد پیام‌ها
* کاهش بار سرور + تجربه بهتر کاربر

---

## **اسلاید 19 – عنوان: Reasons for Migrating Code / Performance**
**ترجمه:**
پشتیبانی از مهاجرت کُد می‌تواند با استفاده از **موازی‌سازی (Parallelism)** کارایی را بهتر کند، بدون اینکه پیچیدگی‌های معمول برنامه‌نویسی موازی را داشته باشیم.
مثال: جست‌وجوی اطلاعات در وب.
می‌توان یک پرس‌وجو را به‌صورت یک برنامه کوچک متحرک (Mobile Program) به نام **عامل متحرک (Mobile Agent)** پیاده‌سازی کرد که از سایتی به سایت دیگر حرکت می‌کند.
با ساخت چند کپی از این برنامه و فرستادن هر کدام به سایت‌های مختلف، می‌توان نسبت به اجرای یک نمونه، تقریباً افزایش سرعت خطی (Linear Speedup) گرفت.
**جزوه:**

* Mobile agent برای انجام کار نزدیک مقصدهای مختلف
* تکثیر agentها ⇒ parallel search
  **تعاریف/توضیحات کوتاه:**
* Mobile Agent: برنامه‌ای که می‌تواند بین گره‌ها جابه‌جا شود و در مقصد اجرا شود.
  **Key Points:**
* استفاده از parallelism بدون دردسر زیاد
* Mobile agent = برنامه جابه‌جاشونده
* چند agent ⇒ سرعت بیشتر

---

## **اسلاید 20 – عنوان: Reasons for Migrating Code / Flexibility**
**ترجمه:**
اگر کُد بتواند بین ماشین‌های مختلف حرکت کند، می‌شود سیستم‌های توزیع‌شده را **به‌صورت پویا (Dynamically)** پیکربندی کرد.
مثال: فرض کنید سرور یک رابط استاندارد (Standardized Interface) برای فایل‌سیستم دارد. برای اینکه کلاینت‌های راه‌دور بتوانند به فایل‌سیستم دسترسی داشته باشند، سرور از یک پروتکل اختصاصی (Proprietary Protocol) استفاده می‌کند…
**جزوه:**

* Flexibility یعنی: سیستم در زمان اجرا (runtime) خودش را با شرایط/پروتکل/سرویس‌های مختلف تنظیم کند
* Code mobility کمک می‌کند “قابلیت” به جای “نصب دائمی” منتقل شود
  **تعاریف/توضیحات کوتاه:**
* Proprietary protocol: پروتکل غیرعمومی/اختصاصی یک شرکت/سیستم.
  **Key Points:**
* مهاجرت کُد ⇒ پیکربندی پویا
* مناسب برای تغییرات سریع سرویس‌ها

---

## **اسلاید 21 – عنوان: Reasons for Migrating Code / Flexibility**
**ترجمه:**
یک راه جایگزین این است که سرور پیاده‌سازی مورد نیاز کلاینت را دقیقاً زمانی ارائه دهد که لازم می‌شود؛ یعنی وقتی کلاینت به سرور bind می‌شود.
در آن نقطه، کلاینت به‌صورت پویا پیاده‌سازی را دانلود می‌کند، مقداردهی اولیه (Initialization) لازم را انجام می‌دهد و سپس سرور را فراخوانی می‌کند.
(شکل) اصل پیکربندی پویا: کلاینت ابتدا نرم‌افزار لازم را می‌گیرد و بعد سرور را صدا می‌زند.
**جزوه:**

* “Download on demand” برای کلاینت
* کاهش نیاز به پیش‌نصب همه چیز
  **تعاریف/توضیحات کوتاه:**
* Binding (Bind): متصل/مرتبط شدن کلاینت با سرویس/سرور برای استفاده از آن.
  **Key Points:**
* نرم‌افزار لازم در لحظه دانلود می‌شود
* ابتدا fetch ⇒ سپس invoke

---

## **اسلاید 22 – عنوان: Reasons for Migrating Code / Flexibility**
**ترجمه:**
این مدلِ جابه‌جایی پویا کُد نیاز دارد پروتکل دانلود و مقداردهی اولیه استاندارد باشد.
کلاینت‌ها لازم نیست از قبل همه نرم‌افزارهای ارتباط با سرورها را نصب داشته باشند؛ نرم‌افزار در صورت نیاز وارد می‌شود و وقتی لازم نبود کنار گذاشته می‌شود.
مزیت دیگر: تا وقتی رابط‌ها استاندارد باشند، می‌توان پروتکل کلاینت-سرور و پیاده‌سازی‌اش را هرچقدر خواست تغییر داد؛ این تغییرات کلاینت‌های موجود را خراب نمی‌کند.
**عیب:** امنیت پایین (Low security).
**جزوه:**

* شرط موفقیت: استانداردسازی دانلود/راه‌اندازی کُد
* مزایا: عدم نیاز به نصب دائمی + امکان تغییر پروتکل بدون شکستن کلاینت‌ها
* ریسک: امنیت (کُد دانلودی می‌تواند مخرب باشد)
  **تعاریف/توضیحات کوتاه:**
* Code download risk: نیاز به sandbox/امضا/اعتبارسنجی.
  **Key Points:**
* استاندارد بودن مکانیزم دانلود ضروری است
* تغییرات سمت سرور کلاینت‌های قدیمی را کمتر می‌شکند
* امنیت چالش اصلی است

---

## **اسلاید 23 – عنوان: Code migration types**
**ترجمه:**
انواع کلی مهاجرت:

* تبادل داده بین فرایندها (Exchanging data between processes)
* جابه‌جایی برنامه‌ها بین ماشین‌ها با هدف اجرای آن‌ها در مقصد (Moving programs between machines to be executed at the target)
  **جزوه:**
* سطح 1: فقط دیتا جابه‌جا می‌شود
* سطح 2: خود کُد/برنامه جابه‌جا می‌شود و در مقصد اجرا می‌شود
  **تعاریف/توضیحات کوتاه:**
* Mobility: توانایی انتقال کُد/وضعیت اجرا بین ماشین‌ها.
  **Key Points:**
* Data shipping vs Code shipping
* اجرای برنامه در مقصد، سناریوی “مهاجرت کُد” واقعی است

---

## **اسلاید 24 – عنوان: A process consists of three segments**
**ترجمه:**
یک فرایند از سه بخش (Segment) تشکیل می‌شود:

* **بخش کُد (Code Segment):** شامل دستورالعمل‌های برنامه در حال اجرا.
* **بخش منبع/منابع (Resource Segment):** شامل ارجاع به منابع خارجی مورد نیاز فرایند مثل فایل‌ها، چاپگرها، دستگاه‌ها، فرایندهای دیگر و…
* **بخش اجرا (Execution Segment):** برای نگهداری وضعیت فعلی اجرای فرایند؛ شامل داده‌های خصوصی، پشته (Stack) و شمارنده برنامه (Program Counter).
  **جزوه:**
* برای مهاجرت قوی، فقط کُد کافی نیست؛ وضعیت اجرا هم مهم است
* Resource segment معمولاً سخت‌ترین بخشِ قابل‌انتقال است
  **تعاریف/توضیحات کوتاه:**
* Program Counter (PC): آدرس دستور بعدی برای اجرا.
  **Key Points:**
* Process = Code + Resources + Execution state
* Execution segment شامل stack و PC

---

## **اسلاید 25 – عنوان: Models for Code Migration**
**ترجمه:**
**تحرک ضعیف (Weak Mobility):**
در این مدل فقط بخش کُد (و شاید داده‌های اولیه) منتقل می‌شود.
ویژگی مهم: برنامه منتقل‌شده همیشه از یکی از چند نقطه شروع از پیش تعریف‌شده اجرا را آغاز می‌کند.
مثال: اپلت‌های جاوا (Java Applets) که همیشه از ابتدای برنامه شروع می‌شوند.
مزیت: سادگی.
Weak mobility فقط نیاز دارد ماشین مقصد بتواند آن کُد را اجرا کند؛ یعنی کُد باید قابل‌حمل (Portable) باشد.
**جزوه:**

* Weak mobility = انتقال code (+ init data) بدون انتقال “جای دقیق اجرای فعلی”
* شروع اجرا از entry point مشخص
  **تعاریف/توضیحات کوتاه:**
* Portable code: کُدی که روی سیستم‌های مختلف قابل اجراست (مثلاً با VM مثل Java).
  **Key Points:**
* انتقال فقط code
* شروع از نقطه از پیش تعیین‌شده
* ساده‌تر از strong mobility

---

## **اسلاید 26 – عنوان: Models for Code Migration (continue)**
**ترجمه:**
**تحرک قوی (Strong Mobility):**
در سیستم‌هایی که strong mobility را پشتیبانی می‌کنند، بخش اجرا (Execution Segment) هم قابل انتقال است.
ویژگی کلیدی: یک فرایند در حال اجرا می‌تواند متوقف شود، به ماشین دیگر منتقل شود و سپس دقیقاً از همان جایی که متوقف شده بود ادامه دهد.
Strong mobility از weak mobility عمومی‌تر است، اما پیاده‌سازی‌اش خیلی سخت‌تر است.
**جزوه:**

* Strong mobility = انتقال code + execution state
* Resume دقیقاً از نقطه توقف
  **تعاریف/توضیحات کوتاه:**
* Checkpoint/Restore (مفهوم نزدیک): ذخیره وضعیت اجرا و بازیابی در جای دیگر.
  **Key Points:**
* انتقال execution segment هم لازم است
* ادامه از همان نقطه
* پیچیدگی پیاده‌سازی بالا

---

## **اسلاید 27 – عنوان: Migration and Local Resources**
**ترجمه:**
چیزی که مهاجرت کُد را سخت می‌کند این است که بخش منابع (Resource Segment) همیشه نمی‌تواند بدون تغییر همراه دو بخش دیگر منتقل شود.
انواع اتصال فرایند به منبع (Process-to-resource binding):

* اتصال با شناسه (Binding by identifier)
* اتصال با مقدار (Binding by value)
* اتصال با نوع (Binding by types)
  **جزوه:**
* مشکل اصلی migration: منابع محلی/وابستگی‌ها
* باید مشخص کنیم وابستگی برنامه به منابع چقدر “محکم” است
  **تعاریف/توضیحات کوتاه:**
* Binding: میزان وابستگی فرایند به یک منبع مشخص.
  **Key Points:**
* Resource segment همیشه قابل انتقال ساده نیست
* 3 نوع binding معرفی می‌شود

---

## **اسلاید 28 – عنوان: Binding by identifier**
**ترجمه:**
**اتصال با شناسه (Binding by identifier):**
قوی‌ترین نوع اتصال وقتی است که فرایند به یک منبع با شناسه‌اش ارجاع می‌دهد. در این حالت فرایند دقیقاً همان منبع را می‌خواهد و هیچ چیز دیگری جایگزینش نمی‌شود.
مثال: وقتی فرایند از URL برای اشاره به یک وب‌سایت خاص استفاده می‌کند یا به یک FTP server با آدرس اینترنتی‌اش اشاره می‌کند.
**جزوه:**

* Binding by identifier ⇒ سخت‌ترین برای مهاجرت
* چون “همان منبع مشخص” باید در مقصد هم قابل دسترسی باشد
  **تعاریف/توضیحات کوتاه:**
* Identifier: شناسه یکتا مثل URL/IP/ID.
  **Key Points:**
* strongest binding
* جایگزینی‌پذیری تقریباً صفر
* چالش بزرگ برای migration

---

## **اسلاید 29 – عنوان: Binding by value**
**ترجمه:**
**اتصال با مقدار (Binding by value):**
نوع ضعیف‌تری از اتصال وقتی است که فقط “مقدار/محتوا”ی منبع لازم است. در این حالت اگر منبع دیگری همان مقدار را بدهد، اجرای فرایند خراب نمی‌شود.
مثال: وابستگی برنامه به کتابخانه‌های استاندارد (Standard Libraries) مثل کتابخانه‌های C یا Java. این کتابخانه‌ها باید محلی موجود باشند، ولی مکان دقیق‌شان در فایل‌سیستم ممکن است بین سایت‌ها فرق کند.
مهم فایل خاص نیست، بلکه محتوای آن مهم است.
**جزوه:**

* ارزش/محتوا مهم است نه مسیر/فایل خاص
* در مهاجرت، کافی است نسخه سازگار از library در مقصد باشد
  **تعاریف/توضیحات کوتاه:**
* Standard library: مجموعه توابع پایه زبان/سیستم.
  **Key Points:**
* قابل جایگزینی است
* مکان فایل مهم نیست، محتوا مهم است
* migration آسان‌تر از identifier

---

## **اسلاید 30 – عنوان: Binding by types**
**ترجمه:**
**اتصال با نوع (Binding by types):**
ضعیف‌ترین نوع اتصال زمانی است که فرایند فقط اعلام می‌کند به منبعی با یک نوع خاص نیاز دارد.
مثال: اشاره به دستگاه‌های محلی مثل مانیتور، چاپگر و…
**جزوه:**

* فقط “نوع منبع” مهم است
* در مقصد هر منبعی با همان type کافی است
  **تعاریف/توضیحات کوتاه:**
* Type-based requirement: نیاز به کلاس/گروه منبع، نه نمونه مشخص.
  **Key Points:**
* weakest binding
* جایگزینی‌پذیری بالا
* مهاجرت ساده‌تر

---

## **اسلاید 31 – عنوان: Resource-to-machine bindings**
**ترجمه:**
سه نوع اتصال منبع به ماشین (Resource-to-machine bindings):

* **منابع آزاد (Unattached):** به‌راحتی بین ماشین‌ها جابه‌جا می‌شوند؛ معمولاً فایل‌های داده‌ای مرتبط با برنامه مهاجرتی.
* **منابع میخ‌شده/بست‌شده (Fastened):** جابه‌جایی/کپی ممکن است اما پرهزینه است؛ مثال: پایگاه‌داده‌های محلی، وب‌سایت کامل.
* **منابع ثابت (Fixed):** به یک ماشین/محیط خاص گره خورده‌اند و قابل جابه‌جایی نیستند؛ معمولاً دستگاه‌های محلی. مثال دیگر: نقطه پایانی ارتباطی محلی (Local communication endpoint).
  **جزوه:**
* علاوه بر وابستگی process به resource، خود resource هم ممکن است قابل حرکت/غیرقابل حرکت باشد
* Unattached ⇒ بهترین برای migration
* Fixed ⇒ عملاً غیرقابل انتقال
  **تعاریف/توضیحات کوتاه:**
* Local endpoint: مثل سوکت/پورت محلی که به همان سیستم وابسته است.
  **Key Points:**
* Unattached: آسان و ارزان
* Fastened: ممکن ولی گران
* Fixed: غیرقابل انتقال

---

## **اسلاید 32 – عنوان: Self study**
**ترجمه:**
مطالعه‌ی خودخوان: مهاجرت در سیستم‌های ناهمگون (Migration in Heterogeneous Systems).
**جزوه:**

* ناهمگون = معماری/سیستم‌عامل/ABI متفاوت ⇒ migration سخت‌تر (قابل‌حمل بودن کُد و وضعیت اجرا چالش می‌شود).
  **تعاریف/توضیحات کوتاه:**
* Heterogeneous: غیرهمسان (مثلاً x86 در برابر ARM).
  **Key Points:**
* مهاجرت در ناهمگون‌ها پیچیده‌تر است
* به portability و سازگاری سطح پایین نیاز دارد

---

## **اسلاید 33 – عنوان: End of Chapter 3**
**ترجمه:**
پایان فصل ۳.
**جزوه:**

* جمع‌بندی: Threads و مدل‌های پیاده‌سازی (ULT/KLT/LWP) + کاربرد چندنخی در client/server + مبانی code migration و چالش منابع.
  **تعاریف/توضیحات کوتاه:**
* —
  **Key Points:**
* Threads پایه‌ی هم‌زمانی
* Client/Server چندنخی برای کارایی و پاسخ‌گویی
* Code migration تحت تاثیر “وابستگی به منابع” است

----

# **فصل ۴ (Chapter 4: NAMING)**

## **اسلاید 1 – عنوان: Advanced Operating Systems | Chapter 4: NAMING**
**ترجمه:** سیستم‌عامل‌های پیشرفته – فصل ۴: نام‌گذاری (Naming)
**جزوه:**

* شروع فصل «Naming»: اینکه در سیستم‌های توزیع‌شده چطور به موجودیت‌ها اسم می‌دهیم و آن‌ها را پیدا می‌کنیم.
  **تعاریف/توضیحات کوتاه:** Naming یعنی نگاشت (Mapping) بین «نام‌ها» و «مکان/آدرس» یا «شیء/موجودیت» در شبکه.
  **Key Points:**
* آغاز فصل ۴: Naming
* هدف کلی: ارجاع و یافتن موجودیت‌ها در سیستم توزیع‌شده

---

## **اسلاید 2 – عنوان: Contents**
**ترجمه:** سرفصل‌ها:

* نام‌ها، شناسه‌ها و آدرس‌ها (Names, Identifiers, and Addresses)
* سیستم‌های نام‌گذاری تخت (Flat Naming Systems)
* نام‌گذاری ساخت‌یافته (Structured Naming)
* نام‌گذاری مبتنی بر ویژگی (Attribute-based Naming)

  * در Structured Naming: فضای نام (Name spaces)، حل نام و مکانیزم Closure، لینک‌کردن و Mount، پیاده‌سازی فضای نام، توزیع فضای نام، پیاده‌سازی Name Resolution
    **جزوه:**
* نقشه راه فصل:

  1. فرق Name/Identifier/Address
  2. روش‌های Flat برای پیدا کردن موجودیت
  3. ساختار سلسله‌مراتبی و Namespace
  4. جستجو با ویژگی‌ها (attribute,value)
     **تعاریف/توضیحات کوتاه:** Name resolution یعنی تبدیل نام به چیزی قابل استفاده برای دسترسی (مثل آدرس).
     **Key Points:**
* چهار بخش اصلی فصل
* زیرموضوع‌های مهم Structured Naming: Namespace و Name Resolution

---

## **اسلاید 3 – عنوان: Names, Identifiers, and Addresses**
**ترجمه:**

* **Name (نام):** در یک سیستم توزیع‌شده، نام یک رشته از بیت‌ها یا کاراکترهاست که برای اشاره به یک **موجودیت** (Entity) استفاده می‌شود.
* **Entities (موجودیت‌ها):** موجودیت در سیستم توزیع‌شده می‌تواند تقریباً هر چیزی باشد.

  * مثال: میزبان‌ها (hosts)، چاپگرها (printers)، دیسک‌ها (disks)، فایل‌ها (files)، فرایندها (processes)، کاربران (users)، صندوق‌پستی‌ها (mailboxes)، صفحات وب (web pages)، پنجره‌های گرافیکی (graphical windows)، پیام‌ها (messages)، اتصال‌های شبکه (network connections)، و …
    **جزوه:**
* نام = برچسب برای اشاره (Reference)
* Entity = هر چیزی که در سیستم وجود دارد و ممکن است بخواهیم به آن دسترسی داشته باشیم یا عملیاتی روی آن انجام دهیم.
  **تعاریف/توضیحات کوتاه:** Entity لزوماً “شیء فیزیکی” نیست؛ می‌تواند منطقی/نرم‌افزاری هم باشد (مثل process یا connection).
  **Key Points:**
* Name = رشته‌ای برای ارجاع به Entity
* Entity دامنه‌ی بسیار گسترده دارد (فایل، میزبان، کاربر، وب‌پیج، …)

---

## **اسلاید 4 – عنوان: Names, Identifiers, and Addresses (Access Point / Address)**
**ترجمه:**

* می‌توان روی موجودیت‌ها عملیات انجام داد. برای عملیات روی یک موجودیت باید به آن دسترسی پیدا کنیم؛ برای این کار به یک **نقطه دسترسی** (Access point) یا **آدرس** (Address) نیاز داریم.
* یک موجودیت می‌تواند **بیش از یک نقطه دسترسی** داشته باشد.
* مثال تشبیهی: تلفن را می‌توان یک access point برای یک شخص دانست و شماره تلفن معادل address است.
* در سیستم توزیع‌شده، نمونه معمول access point: یک **میزبان (Host)** که یک **سرویس مشخص (Specific server)** را اجرا می‌کند؛ آدرس معمولاً ترکیبی از **IP address** و **Port number** است.
* یک آدرس فقط یک نوع خاص از نام است.
  **جزوه:**
* برای “دسترسی” باید بدانیم از کجا وارد شویم (IP:Port)
* تفاوت مهم: ممکن است یک entity چند access point داشته باشد (مثلاً چند سرور/چند اینترفیس)
  **تعاریف/توضیحات کوتاه:** Access point یعنی «محل/نقطه‌ای که از آن می‌توان به entity رسید»؛ Address همان “مشخصات دسترسی” به آن نقطه است.
  **Key Points:**
* دسترسی به entity نیاز به access point/address دارد
* آدرس معمولاً IP + Port است
* entity ممکن است چند access point داشته باشد

---

## **اسلاید 5 – عنوان: Use the address as a name**
**ترجمه:**

* یک موجودیت ممکن است با گذشت زمان **نقاط دسترسی‌اش تغییر کند**؛ مثلاً یک کامپیوتر موبایل با جابه‌جایی، IP جدید می‌گیرد.
* بنابراین اگر از **آدرس به عنوان نام** برای اشاره به entity استفاده کنیم، به محض اینکه access point تغییر کند یا آدرس به entity دیگری اختصاص داده شود، **ارجاع نامعتبر (Invalid reference)** خواهیم داشت.
* همچنین اگر entity بیش از یک access point داشته باشد، مشخص نیست کدام آدرس را باید به عنوان مرجع استفاده کنیم.
* نتیجه: نامی که از آدرس‌های entity **مستقل** باشد معمولاً استفاده‌اش **ساده‌تر و منعطف‌تر** است.
  **جزوه:**
* مشکل Address-as-Name:

  * تغییر مکان/شبکه ⇒ IP عوض می‌شود ⇒ reference می‌شکند
  * چند آدرس ⇒ ambiguity (ابهام)
* راه بهتر: نام پایدار (Stable name) جدا از location/address
  **تعاریف/توضیحات کوتاه:** این دقیقاً ایده‌ی «location independence» است: هویت (Identity) را از مکان (Location) جدا کن.
  **Key Points:**
* آدرس ناپایدار است (ممکن است عوض شود)
* آدرس می‌تواند دوباره استفاده شود (Reassigned)
* نام مستقل از آدرس ⇒ پایدارتر و منعطف‌تر

---

## **اسلاید 6 – عنوان: Identifier**
**ترجمه:**

* **Identifier (شناسه):** یک شناسه‌ی واقعی، نامی است که برای **شناسایی یکتا** (Uniquely identify) یک موجودیت استفاده می‌شود.
* **ویژگی‌های شناسه واقعی (Properties of a true identifier):**

  1. یک شناسه به **حداکثر یک موجودیت** اشاره می‌کند.
  2. هر موجودیت با **حداکثر یک شناسه** مورد اشاره قرار می‌گیرد.
  3. یک شناسه همیشه به **همان موجودیت** اشاره می‌کند (یعنی **هرگز دوباره استفاده نمی‌شود** / never reused).
* با استفاده از شناسه‌ها، اشاره‌ی بدون ابهام به یک entity خیلی ساده‌تر می‌شود.
  **جزوه:**
* Identifier = هویت پایدار (Stable identity)
* سه شرط طلایی: یکتا بودن، یک-به-یک بودن، و عدم reuse
  **تعاریف/توضیحات کوتاه:** تفاوت Identifier با Name معمولی این است که Identifier باید «همیشه و فقط» به همان entity اشاره کند.
  **Key Points:**
* Identifier برای شناسایی یکتا است
* One-to-one mapping بین entity و identifier
* identifier نباید reuse شود

---

## **اسلاید 7 – عنوان: Types of Naming Systems**
**ترجمه:**

* **Flat naming (نام‌گذاری تخت):** شناسه فقط یک رشته بیت تصادفی (Random bit string) است و هیچ اطلاعاتی درباره اینکه چطور به entity برسیم ندارد.
* **Structured naming (نام‌گذاری ساخت‌یافته):** از نام‌های ساده و قابل‌خواندن برای انسان (Human-readable) تشکیل می‌شود؛ مثل نام‌گذاری فایل‌ها و نام میزبان‌ها در اینترنت.
* **Attribute-based naming (نام‌گذاری مبتنی بر ویژگی):** entity با جفت‌های (Attribute, Value) توصیف می‌شود؛ کاربر با محدود کردن بعضی ویژگی‌ها می‌تواند بهتر جستجو کند.
  **جزوه:**
* Flat: هویت هست، اطلاعات مکانی داخلش نیست ⇒ باید جدا resolve شود.
* Structured: اسم‌ها معنی/ساختار دارند ⇒ پیمایش/سلسله‌مراتب.
* Attribute-based: مثل سرچ/کوئری با ویژگی‌ها.
  **تعاریف/توضیحات کوتاه:** Flat معمولاً برای ماشین مناسب‌تر است؛ Structured برای انسان و سلسله‌مراتب؛ Attribute-based برای جستجوی انعطاف‌پذیر.
  **Key Points:**
* سه مدل اصلی نام‌گذاری: Flat / Structured / Attribute-based
* Flat بدون اطلاعات مکانی
* Attribute-based مبتنی بر (attribute,value)

---

## **اسلاید 8 – عنوان: Flat Naming Systems**
**ترجمه:** روش‌های رایج در نام‌گذاری تخت:

* پخش همگانی و چندپخشی (Broadcasting and multicasting)
* اشاره‌گرهای هدایت (Forwarding pointers)
* رویکردهای مبتنی بر خانه (Home-based approaches)
* جدول‌های هش توزیع‌شده (Distributed hash tables)
* رویکردهای سلسله‌مراتبی (Hierarchical approaches)
  **جزوه:**
* در Flat naming باید یک سازوکار برای پیدا کردن آدرس فعلی entity داشته باشیم (Lookup/Resolution).
* این اسلاید فقط فهرست روش‌هاست؛ هرکدام trade-off دارند (مقیاس‌پذیری، هزینه پیام، پیچیدگی، …).
  **تعاریف/توضیحات کوتاه:** DHT یعنی ساختار توزیع‌شده برای نگاشت کلید→مقدار (key→value) در شبکه.
  **Key Points:**
* Flat naming نیازمند روش resolution است
* 5 خانواده روش برای lookup معرفی شد

---

## **اسلاید 9 – عنوان: Broadcasting/Multicasting**
**ترجمه:**

* یک LAN را در نظر بگیرید که امکان **broadcast** کارآمد دارد.
* پیامی شامل هویت entity برای همه ماشین‌ها broadcast می‌شود.
* فقط ماشین‌هایی که می‌توانند دسترسی به آن entity بدهند، پاسخی شامل آدرس access point می‌فرستند.

  * مثال: **ARP (Address Resolution Protocol)**
* **مشکل:**

  * broadcasting برای شبکه‌های بزرگ مناسب نیست
  * پهنای‌باند هدر می‌رود (Bandwidth is wasted)
* برای شبکه‌های بزرگ‌تر، روش کارآمدتر **multicasting** است؛ فقط یک گروه محدود درخواست را دریافت می‌کند.

  * مثال: در سطح پیوند داده در شبکه‌های اترنت (Data-link level in Ethernet networks)
    **جزوه:**
* Broadcast: ساده ولی پرهزینه و غیرمقیاس‌پذیر
* Multicast: هدفمندتر ⇒ کاهش ترافیک
* ARP نمونه کلاسیک resolution محلی است.
  **تعاریف/توضیحات کوتاه:** Broadcast یعنی ارسال به همه؛ Multicast یعنی ارسال به اعضای یک گروه مشخص.
  **Key Points:**
* Broadcast مناسب LAN کوچک
* در شبکه بزرگ ⇒ اتلاف bandwidth
* Multicast راه بهینه‌تر برای گروه محدود

---

## **اسلاید 10 – عنوان: Forwarding Pointers**
**ترجمه:**

* وقتی یک entity از A به B منتقل می‌شود، در A یک ارجاع (Reference) به مکان جدیدش در B باقی می‌گذارد.
* مزیت اصلی این روش **سادگی (Simplicity)** است:

  * به محض اینکه entity با سرویس نام‌گذاری سنتی پیدا شد، کلاینت می‌تواند با دنبال کردن زنجیره‌ی اشاره‌گرهای هدایت (Chain of forwarding pointers)، آدرس فعلی را پیدا کند.
* مثال: اشیای راه‌دور (Remote objects) که می‌توانند از یک میزبان به میزبان دیگر حرکت کنند.
  **جزوه:**
* ایده: “ردپا” بگذار تا هرکس رفت دنبال‌ات، به مقصد جدید هدایت شود.
* Resolution: locate اولیه + follow pointers تا current location
* نکته امتحانی: این روش ساده است ولی ممکن است زنجیره طولانی شود (هزینه lookup بالا می‌رود) — (این نکته در اسلایدهای بعد معمولاً تکمیل می‌شود).
  **تعاریف/توضیحات کوتاه:** Forwarding pointer مثل «آدرس جدیدم اینجاست» است که در محل قبلی گذاشته می‌شود.
  **Key Points:**
* مهاجرت entity ⇒ گذاشتن reference در مکان قبلی
* مزیت: سادگی
* یافتن آدرس فعلی با دنبال کردن chain

---

اگر اوکیه، پیام بعدی ## **اسلاید 11 تا 20 فصل ۴** رو ادامه می‌دم.

---

## **اسلاید 11 – عنوان: Forwarding Pointers**
**ترجمه:**

* یک *server stub* یا یک ارجاع محلی به شیء واقعی دارد، یا یک ارجاع محلی به *remote client stub* مربوط به آن شیء.
* هر زمان شیء از آدرس **A** به **B** منتقل شود، در **A** یک *client stub* از خودش باقی می‌گذارد و در **B** یک *server stub* نصب می‌کند که به آن ارجاع می‌دهد.
* این کار باعث می‌شود مهاجرت (migration) برای کلاینت کاملاً *شفاف* (transparent) باشد.

**جزوه:**

* ایده‌ی اصلی: با گذاشتن «ردپا/اشاره‌گر انتقال» بعد از جابه‌جایی، کلاینت هنوز با همان نام/ارجاع قبلی می‌تواند به شیء برسد.
* ساختار:

  * **در مقصد (B):** server stub → اشاره به شیء
  * **در مبدأ (A):** client stub → اشاره به مقصد بعدی

**تعاریف/توضیحات کوتاه:**

* **Stub (استاب)**: کدی/شیئی واسط برای مخفی‌کردن جزئیات ارتباط (مثل پروکسی).
* **Transparent migration**: جابه‌جایی بدون اینکه کلاینت متوجه تغییر مکان شود.

**Key Points:**

* Forwarding pointer با stubها مهاجرت را برای کلاینت شفاف می‌کند.
* در مبدأ ردپا باقی می‌ماند و در مقصد ارجاع واقعی برقرار می‌شود.

---

## **اسلاید 12 – عنوان: Forwarding Pointers (important drawbacks)**
**ترجمه:**
**مشکلات (Problems):**

1. اگر اقدام خاصی انجام نشود، زنجیره‌ی یک موجودیت بسیار متحرک (highly mobile entity) آن‌قدر طولانی می‌شود که پیدا کردنش بسیار پرهزینه (prohibitively expensive) خواهد شد.
2. همه‌ی مکان‌های میانی در زنجیره باید تا هر زمانی که لازم است بخش خودشان از زنجیره‌ی forwarding pointers را نگه دارند.
3. عیب سوم (مرتبط) آسیب‌پذیری در برابر قطع لینک‌ها (broken links) است؛ اگر هر forwarding pointer به هر دلیلی از دست برود، دیگر دسترسی به موجودیت ممکن نیست.

* مهم است زنجیره‌ها نسبتاً **کوتاه** باشند و forwarding pointerها **مقاوم/robust** باشند.

**جزوه:**

* سه مشکل کلیدی:

  * **طولانی‌شدن زنجیره** ⇒ افزایش زمان/هزینه‌ی lookup
  * **هزینه‌ی نگهداری در نقاط میانی** ⇒ هر گره باید state نگه دارد
  * **شکنندگی** ⇒ با قطع یک حلقه، کل مسیر می‌ریزد
* نتیجه‌ی طراحی: باید **chain کوتاه** + **مکانیزم مقاوم‌سازی** داشته باشیم.

**تعاریف/توضیحات کوتاه:**

* **Broken link** یعنی یکی از گره‌های واسط حذف/خراب شود و مسیر هدایت قطع گردد.

**Key Points:**

* زنجیره‌ی بلند ⇒ lookup گران.
* گره‌های میانی باید state نگه دارند.
* قطع یک اشاره‌گر می‌تواند دسترسی را صفر کند.

---

## **اسلاید 13 – عنوان: Home-Based Approach**
**ترجمه:**

* یک روش محبوب برای پشتیبانی از موجودیت‌های متحرک در شبکه‌های بزرگ این است که یک **home location** معرفی کنیم که مکان فعلی (current location) موجودیت را دنبال می‌کند.
* در عمل، home location معمولاً همان جایی انتخاب می‌شود که موجودیت در آن **ایجاد** (created) شده است.
* روش home-based به‌عنوان یک سازوکار پشتیبان (fall-back mechanism) برای سرویس‌های مکانی مبتنی بر forwarding pointers استفاده می‌شود.

**جزوه:**

* ایده: به جای زنجیره‌ی بلند، یک «نقطه‌ی خانه» داریم که همیشه آخرین مکان را می‌داند.
* کاربرد: وقتی forwarding pointer مشکل‌ساز است، home-based مثل **مرجع مرکزی** عمل می‌کند.

**تعاریف/توضیحات کوتاه:**

* **Home location**: مرجعی که رکورد مکان (location record) موجودیت را نگه می‌دارد.

**Key Points:**

* معرفی home location برای track کردن مکان فعلی.
* معمولاً محل ایجاد موجودیت = home.
* نقش fallback برای روش‌های دیگر.

---

## **اسلاید 14 – عنوان: Home-Based Approach (Mobile IP)**
**ترجمه:**

* در **Mobile IP** هر میزبان (host) یک آدرس خانگی ثابت (**home address**) دارد.
* وقتی میزبان به شبکه‌ای دیگر برود، یک آدرس موقت به نام **care-of address** می‌گیرد.
* موجودی به نام **home agent** در شبکه‌ی خانگی وجود دارد که نگاشتِ home address → care-of address را نگه می‌دارد.

**جزوه:**

* سه جزء اصلی:

  * **Home address** (ثابت)
  * **Care-of address** (وابسته به محل فعلی)
  * **Home agent** (پیگیر مکان و هدایت‌کننده)

**تعاریف/توضیحات کوتاه:**

* **Care-of address**: آدرس نماینده‌ی میزبان در شبکه‌ی فعلی (فعلاً اینجاست).

**Key Points:**

* Mobile IP با home address ثابت + care-of address متغیر کار می‌کند.
* Home agent نگاشت مکان را نگه می‌دارد.

---

## **اسلاید 15 – عنوان: Home-Based Approach (tunneling in Mobile IP)**
**ترجمه:**

* بسته‌ها ابتدا به **home address** می‌آیند.
* سپس توسط **home agent** به **care-of address** تونل (tunnel) می‌شوند تا به محل فعلی برسند.

**جزوه:**

* مسیر معمول: Sender → home network → home agent → (tunnel) → foreign network → mobile host
* نکته‌ی مهم: home agent نقش «واسط اجباری» پیدا می‌کند.

**تعاریف/توضیحات کوتاه:**

* **Tunneling**: کپسوله‌سازی بسته‌ها برای عبور از مسیر خاص تا مقصد واقعی.

**Key Points:**

* home agent ترافیک را به مکان فعلی هدایت می‌کند.
* تونلینگ راه اصلی رساندن بسته به care-of address است.

---

## **اسلاید 16 – عنوان: Home-Based Approach (drawbacks)**
**ترجمه (مفهومی مطابق اسلاید):**

* یک ضعف مهم می‌تواند مسیر غیرمستقیم و افزایش تأخیر باشد (مثلاً بسته‌ها مجبورند از home عبور کنند).
* همچنین home location/home agent یک نقطه‌ی حساس (single point) برای نگهداری رکورد مکان است.

**جزوه:**

* عیب‌های رایج:

  * **Triangle routing / مسیر طولانی‌تر** ⇒ latency بیشتر
  * **وابستگی به home agent** ⇒ گلوگاه/نقطه شکست

**تعاریف/توضیحات کوتاه:**

* **Triangle routing**: مسیر غیرمستقیم که به‌جای رفتن مستقیم به مقصد، از home عبور می‌کند.

**Key Points:**

* هزینه‌ی عملکردی به‌خاطر مسیر غیرمستقیم.
* اتکا به home agent می‌تواند گلوگاه شود.

---

## **اسلاید 17 – عنوان: Distributed Hash Tables**
**ترجمه:**

* یک نوع بسیار موفق از سیستم‌های نام‌گذاری (naming system) به نام **Distributed Hash Table (DHT)** وجود دارد.
* در DHT نام‌ها معمولاً *Flat* هستند و با یک فضای شناسه (identifier space) و تابع هش توزیع می‌شوند.

**جزوه:**

* ایده: نام (کلید/key) را به یک شناسه هش می‌کنیم و آن را روی گره‌ها پخش می‌کنیم.
* نتیجه: **lookup مقیاس‌پذیر** بدون دایرکتوری مرکزی.

**تعاریف/توضیحات کوتاه:**

* **DHT**: ساختار داده‌ی توزیع‌شده برای نگاشت **key → node/address**.

**Key Points:**

* DHT = نام‌گذاری/یافتن توزیع‌شده و مقیاس‌پذیر.
* معمولاً نام‌ها flat هستند و با hash مدیریت می‌شوند.

---

## **اسلاید 18 – عنوان: Distributed Hash Tables (Chord lookup idea)**
**ترجمه:**

* چگونه کلید **k** را به آدرس **succ(k)** به‌صورت کارا resolve کنیم؟
* جستجوی دودویی بدون کران (Unbounded binary search): هر گره یک **finger table** با حداکثر **m** ورودی نگه می‌دارد.
* فرمول:  [
  FT_p[i] = succ(p + 2^{i-1})
  ]
* ورودی iام به اولین گره بعد از p اشاره می‌کند که حداقل به اندازه‌ی (2^{i-1}) جلوتر است؛ این‌ها میان‌بُرهای نمایی (exponentially increasing short-cuts) در فضای شناسه‌اند.
* برای lookup کلید k، گره p درخواست را به گره q با اندیس j در finger table می‌فرستد که:
  [
  q = FT_p[j] \le k < FT_p[j+1]
  ]
* از حساب پیمانه‌ای (modulo arithmetic) استفاده می‌شود.

**جزوه:**

* finger table = لیست میان‌بُرها برای پرش‌های 1،2،4،8،… در فضای شناسه.
* هدف: کاهش تعداد hopها هنگام یافتن succ(k).

**تعاریف/توضیحات کوتاه:**

* **succ(k)**: اولین گره‌ای که شناسه‌اش ≥ k است (در حلقه).
* **Modulo arithmetic**: محاسبه روی حلقه (wrap-around).

**Key Points:**

* (FT_p[i]=succ(p+2^{i-1})) پایه‌ی میان‌بُرهای Chord است.
* انتخاب q طوری است که k بین دو entry قرار گیرد.
* محاسبات روی حلقه‌ی شناسه انجام می‌شود.

---

## **اسلاید 19 – عنوان: Distributed Hash Tables (example in Chord)**
**ترجمه:**

* شکل نشان می‌دهد چگونه مثلاً **کلید 26 از گره 1** و **کلید 12 از گره 28** در سیستم Chord resolve می‌شود، با استفاده از finger tableها و پرش‌های چندمرحله‌ای.

**جزوه:**

* در مثال، مسیرهای قرمز/آبی نشان‌دهنده‌ی hopهای lookup هستند.
* هر hop با استفاده از نزدیک‌ترین میان‌بُر مناسب در finger table انجام می‌شود.

**تعاریف/توضیحات کوتاه:**

* اصل کار: در هر قدم «به جلوترین گره‌ای برو که از k رد نشود».

**Key Points:**

* مثال عملی از lookup با finger table.
* مسیر lookup چند hop دارد ولی سریع‌تر از پیمایش خطی است.

---

## **اسلاید 20 – عنوان: Hierarchical Approaches**
**ترجمه:**

* در طرح سلسله‌مراتبی (hierarchical scheme) شبکه به مجموعه‌ای از **domain**ها تقسیم می‌شود.
* یک domain سطح بالا (top-level) کل شبکه را پوشش می‌دهد.
* هر domain می‌تواند به چند subdomain کوچک‌تر تقسیم شود.
* پایین‌ترین سطح، **leaf domain** نام دارد (مثلاً یک LAN یا یک سلول شبکه موبایل).
* هر domain D یک **directory node** مرتبط به نام **dir(D)** دارد که موجودیت‌های آن domain را track می‌کند؛ بنابراین یک درخت از directory nodeها شکل می‌گیرد.
* directory node دامنه‌ی سطح بالا (root domain) یعنی **root (directory) node** درباره‌ی همه‌ی موجودیت‌ها اطلاع دارد.

**جزوه:**

* ساختار درختی: Root domain → subdomainها → leaf domain
* هر سطح یک directory node دارد که مکان/اطلاعات موجودیت‌ها را نگه می‌دارد.

**تعاریف/توضیحات کوتاه:**

* **Leaf domain**: کوچک‌ترین ناحیه مدیریتی/شبکه‌ای در سلسله‌مراتب.

**Key Points:**

* تقسیم شبکه به domainها برای مقیاس‌پذیری.
* dir(D) برای هر domain، و root dir برای کل سیستم.

---

## **اسلاید 21 – عنوان: Hierarchical Approaches (location records)**
**ترجمه:**

* **root node** برای هر موجودیت یک **location record** دارد.
* هر location record یک اشاره‌گر به **directory node** سطح پایین‌تر نگه می‌دارد که نشان می‌دهد موجودیت اکنون در کدام زیردامنه قرار دارد.

**جزوه:**

* مکان‌یابی مرحله‌ای: از root شروع می‌کنی، اشاره‌گر به زیرسطح می‌گیری، تا به leaf برسی.
* رکورد مکان در هر سطح “به سطح بعدی” راهنمایی می‌کند.

**تعاریف/توضیحات کوتاه:**

* **Location record**: رکوردی که مسیر/اشاره‌گرهای لازم برای رسیدن به مکان فعلی را نگه می‌دارد.

**Key Points:**

* root برای هر entity رکورد مکان دارد.
* رکوردها به directory node سطح پایین‌تر اشاره می‌کنند.

---

## **اسلاید 22 – عنوان: Hierarchical Approaches (replication)**
**ترجمه:**

* اگر یک موجودیت در چند مکان تکرار (replicated) شده باشد، ممکن است برایش **چند آدرس** وجود داشته باشد.
* location record می‌تواند به **بیش از یک** زیردامنه اشاره کند (برای نگهداری مکان‌های مختلف replicaها).

**جزوه:**

* در replication، lookup باید بتواند چند مقصد ممکن را برگرداند.
* رکورد مکان می‌تواند «لیست اشاره‌گرها» باشد نه فقط یکی.

**تعاریف/توضیحات کوتاه:**

* **Replication**: نگهداری چند کپی از یک موجودیت در مکان‌های مختلف برای دسترس‌پذیری/کارایی.

**Key Points:**

* replication ⇒ ممکن است چند location همزمان وجود داشته باشد.
* location record می‌تواند چند pointer داشته باشد.

---

## **اسلاید 23 – عنوان: Structured Naming**
**ترجمه:**

* نام‌های ساخت‌یافته (structured names) معمولاً به شکل یک مسیر (path) در یک **نام‌فضا (name space)** سازمان‌دهی می‌شوند (مثل سیستم فایل یا DNS).

**جزوه:**

* structured naming یعنی نام‌ها خودشان **ساختار سلسله‌مراتبی** دارند (برخلاف flat name).
* مزیت: مدیریت و سازمان‌دهی ساده‌تر.

**تعاریف/توضیحات کوتاه:**

* **Name space**: مجموعه‌ی نام‌ها و روابطشان (معمولاً درخت/گراف).

**Key Points:**

* structured name شبیه مسیر است.
* معمولاً با name space سلسله‌مراتبی همراه است.

---

## **اسلاید 24 – عنوان: Structured Naming (graph model)**
**ترجمه:**

* نام‌ها را می‌توان به صورت یک **گراف نام‌گذاری (naming graph)** دید.
* یک نام مسیرگونه (path name) دنباله‌ای از labelهاست که از یک گره شروع می‌کند و به گره/منبع مقصد می‌رسد.

**جزوه:**

* مدل: Nodeها = دایرکتوری/دامنه‌ها، یال‌ها = labelها
* path name = دنبال‌کردن یال‌های برچسب‌دار

**تعاریف/توضیحات کوتاه:**

* **Label**: نام یال/جزء مسیر (مثل “nl”، “vu”، “cs”).

**Key Points:**

* نام‌گذاری ساخت‌یافته قابل مدل‌سازی با گراف است.
* path name = sequence از labelها.

---

## **اسلاید 25 – عنوان: Structured Naming (path name notation)**
**ترجمه:**

* نمایش یک نام مسیرگونه:
  [
  N:\langle label_1, label_2, \dots, label_n \rangle
  ]
* که در آن **N** گره شروع (starting node) است و دنباله‌ی labelها مسیر را مشخص می‌کند.

**جزوه:**

* این نمایش دقیقاً مثل «از این نقطه شروع کن و این labelها را پشت سر هم دنبال کن».

**تعاریف/توضیحات کوتاه:**

* **Starting node**: نقطه‌ی شروع حل نام (مثل root یا یک گره محلی).

**Key Points:**

* فرم استاندارد path name: (N:\langle...\rangle)
* ترتیب labelها تعیین‌کننده‌ی مسیر است.

---

## **اسلاید 26 – عنوان: Name Resolution & Closure Mechanism**
**ترجمه:**

* **Name resolution** یعنی تبدیل یک نام (name) به موجودیت/آدرس متناظر.
* **Closure mechanism** یعنی بعد از resolve شدن، سیستم بتواند «با نتیجه چه کار کند» (مثلاً اگر نتیجه یک فایل/سرویس روی پروتکل خاصی است، بتواند به آن دسترسی بدهد).

**جزوه:**

* دو مرحله‌ی مهم:

  1. **Resolve**: اسم → اشاره‌گر/آدرس
  2. **Closure**: استفاده از نتیجه (مثلاً اتصال با FTP/HTTP/…)

**تعاریف/توضیحات کوتاه:**

* Closure یعنی نتیجه‌ی resolution قابل «عملیاتی شدن» باشد (نه صرفاً یک نام دیگر).

**Key Points:**

* Name resolution: نام → مقصد.
* Closure: امکان دسترسی/استفاده از مقصد.

---

## **اسلاید 27 – عنوان: Naming graph (example)**
**ترجمه:**

* شکل، یک گراف نام‌گذاری با root و labelهای مختلف را نشان می‌دهد؛ نمونه‌ای از اینکه مسیر با labelها چگونه گره‌ها را طی می‌کند.

**جزوه:**

* دید گرافی کمک می‌کند تفاوت مسیرها، شاخه‌ها و نقطه‌ی شروع (root یا غیرroot) روشن شود.

**تعاریف/توضیحات کوتاه:**

* در naming graph ممکن است زیرگراف‌ها به سرویس‌ها/دایرکتوری‌های متفاوت برسند.

**Key Points:**

* گراف نام‌گذاری = پایه‌ی تحلیل structured names.
* مسیر = حرکت روی یال‌های labelدار.

---

## **اسلاید 28 – عنوان: Mounting in distributed name spaces**
**ترجمه:**

* سیستم‌ها می‌توانند نام‌فضاهای جدا را به هم **mount** کنند (مثل mount شدن یک فایل‌سیستم راه‌دور در یک شاخه).
* نتیجه: کاربر یک نام‌فضای یکپارچه می‌بیند، حتی اگر منابع روی چند سیستم باشند.

**جزوه:**

* mounting یعنی «وصل کردن ریشه/زیرشاخه‌ی یک نام‌فضا به نقطه‌ای داخل نام‌فضای دیگر».
* هدف: یکپارچه‌سازی و شفافیت برای کاربر.

**تعاریف/توضیحات کوتاه:**

* **Mount point**: نقطه‌ای که نام‌فضای دیگر به آن متصل می‌شود.

**Key Points:**

* mounting نام‌فضاها را ادغام می‌کند.
* کاربر یک فضای واحد می‌بیند.

---

## **اسلاید 29 – عنوان: Mounting (example: protocol-specific access)**
**ترجمه:**

* شکل نشان می‌دهد که یک زیرنام‌فضا ممکن است از طریق یک **پروتکل دسترسی خاص** (specific access protocol) مثل FTP/WWW ارائه شود و در نام‌فضای کلی mount گردد.

**جزوه:**

* mount می‌تواند همراه با «نوع دسترسی» باشد (مثلاً این بخش از نام‌فضا با FTP سرو می‌شود).

**تعاریف/توضیحات کوتاه:**

* **Access protocol**: پروتکل دسترسی به داده/سرویس (FTP, HTTP, …).

**Key Points:**

* mount می‌تواند نام‌فضاهای با پروتکل‌های مختلف را یکجا نشان دهد.
* نام نهایی می‌تواند به منبع راه‌دور ختم شود.

---

## **اسلاید 30 – عنوان: Name Space Distribution (example partitioning)**
**ترجمه:**

* شکل، یک نمونه از تقسیم‌بندی (partitioning) نام‌فضای DNS را به **سه لایه** نشان می‌دهد:

  * **Global layer**
  * **Administrational layer**
  * **Managerial layer**

**جزوه:**

* ایده: به‌خاطر مقیاس بزرگ، name serverها را لایه‌بندی می‌کنیم تا مدیریت و کارایی بهتر شود.

**تعاریف/توضیحات کوتاه:**

* **Partitioning**: تقسیم مسئولیت نگهداری بخش‌های name space بین سرورها/لایه‌ها.

**Key Points:**

* name space بزرگ را به لایه‌ها تقسیم می‌کنند.
* سه لایه: global / administrational / managerial.

---

## **اسلاید 31 – عنوان: Name Space Distribution (why layers?)**
**ترجمه (خلاصه‌ی محتوایی اسلاید):**

* لایه‌بندی باعث می‌شود بخش‌های پایدارتر در بالا و بخش‌های پرتغییرتر در پایین قرار بگیرند؛ هر لایه سیاست نگهداری/کَش متفاوتی دارد.

**جزوه:**

* اصل کلیدی: **هرچه پایین‌تر، تغییرات بیشتر و تعداد گره‌ها بیشتر**.
* پس replication/caching و سرعت پاسخ‌دهی در لایه‌ها متفاوت است.

**تعاریف/توضیحات کوتاه:**

* لایه‌ها کمک می‌کنند “trade-off” بین مقیاس‌پذیری و سرعت/به‌روزرسانی مدیریت شود.

**Key Points:**

* لایه‌بندی = مدیریت بهتر تغییرات و مقیاس.
* لایه‌های بالا پایدارتر، پایین پرتغییرتر.

---

## **اسلاید 32 – عنوان: Name Space Distribution (zones)**
**ترجمه (خلاصه‌ی محتوایی اسلاید):**

* نام‌فضا به ناحیه‌هایی مثل **Zone** تقسیم می‌شود که هرکدام توسط یک/چند name server مدیریت می‌شوند.

**جزوه:**

* Zone واحد مدیریتی/تکثیر در DNS است.
* هر zone می‌تواند رکوردهای خودش را در چند سرور کپی کند.

**تعاریف/توضیحات کوتاه:**

* **Zone**: بخشی از نام‌فضا که مسئولیت مدیریتش با یک مجموعه سرور است.

**Key Points:**

* Zone = واحد مدیریت نام‌فضا.
* سرورها می‌توانند مسئول زیرمجموعه‌ای از درخت باشند.

---

## **اسلاید 33 – عنوان: Name Space Distribution (more on zones)**
**ترجمه (خلاصه):**

* شکل/متن تکمیلی درباره‌ی اینکه zoneها چگونه بخش‌هایی از درخت DNS را پوشش می‌دهند.

**جزوه:**

* zoneها الزاماً «همه‌ی زیرشاخه‌ها» را شامل نمی‌شوند؛ مرزبندی دقیق با سیاست مدیریتی تعیین می‌شود.

**تعاریف/توضیحات کوتاه:**

* zone cut: نقطه‌ای که از آن به بعد یک زیرشاخه توسط مجموعه‌ی دیگری مدیریت می‌شود.

**Key Points:**

* مرز zoneها مهم‌ترین بخش طراحی DNS است.
* zoneها استقلال مدیریتی می‌دهند.

---

## **اسلاید 34 – عنوان: Name Space Distribution (three layers figure)**
**ترجمه:**

* شکل نمونه‌ی لایه‌بندی name space را نشان می‌دهد: ریشه و TLDها در global، سازمان‌ها در administrational، و منابع/فایل‌ها/میزبان‌ها در managerial.

**جزوه:**

* Global: top-levelها (مثل com, edu, …)
* Administrational: درون سازمان‌ها (دانشگاه، شرکت، …)
* Managerial: فایل‌ها، سرویس‌ها، میزبان‌ها (پرتغییرترین)

**تعاریف/توضیحات کوتاه:**

* هرچه پایین‌تر، نیاز به پاسخ سریع‌تر و آپدیت بیشتر.

**Key Points:**

* تصویر دقیق سه‌لایه را نشان می‌دهد.
* managerial پرتغییرترین است.

---

## **اسلاید 35 – عنوان: Name Space Distribution / Global layer**
**ترجمه:**

* لایه‌ی جهانی (Global layer) از **گره‌های سطح‌بالا** تشکیل شده است: یعنی root و گره‌های دایرکتوری نزدیک به root (فرزندانش).
* گره‌های این لایه معمولاً به دلیل **پایداری (stability)** شناخته می‌شوند؛ به این معنی که **جدول‌های دایرکتوری (directory tables)** به ندرت تغییر می‌کنند.
* این گره‌ها ممکن است نماینده‌ی **سازمان‌ها** یا **گروه‌هایی از سازمان‌ها** باشند که نام‌هایشان در name space ذخیره می‌شود.

**جزوه:**

* Global layer: کم‌تعداد، جهانی، تغییر کم
* مناسب برای replication زیاد و caching قوی

**تعاریف/توضیحات کوتاه:**

* **Directory table**: نگاشت labelها به گره/سرور بعدی.

**Key Points:**

* global = root و نزدیک‌های root.
* بسیار پایدار؛ تغییرات کم.

---

## **اسلاید 36 – عنوان: Name Space Distribution / Administrational layer**
**ترجمه:**

* لایه‌ی اداری (Administrational layer) از **directory node**هایی تشکیل می‌شود که همگی در یک **سازمان واحد** مدیریت می‌شوند.
* ویژگی مهم: این گره‌ها نماینده‌ی گروه‌هایی از موجودیت‌ها هستند که به یک سازمان/واحد اداری مشترک تعلق دارند.
* مثال: یک directory node برای هر دپارتمان، یا گره‌ای که همه‌ی میزبان‌ها از آن قابل یافتن باشند.
* گره‌های این لایه نسبتاً **پایدار (relatively stable)** هستند، اما تغییرات معمولاً بیشتر از global layer رخ می‌دهد.

**جزوه:**

* administrational = درون یک سازمان
* تغییرات متوسط، تعداد گره‌ها بیشتر از global

**تعاریف/توضیحات کوتاه:**

* این لایه محل سیاست‌گذاری و مدیریت سازمانی نام‌هاست.

**Key Points:**

* مدیریت داخل یک سازمان.
* نسبتاً پایدار ولی پر تغییرتر از global.

---

## **اسلاید 37 – عنوان: Name Space Distribution / Managerial layer**
**ترجمه:**

* لایه‌ی مدیریتی (Managerial layer) شامل گره‌هایی است که معمولاً **به طور منظم تغییر می‌کنند**.
* مثال: گره‌های نماینده‌ی میزبان‌های شبکه محلی در این لایه‌اند.
* همچنین گره‌های نماینده‌ی فایل‌های اشتراکی (libraries/binaries) و دایرکتوری/فایل‌های تعریف‌شده توسط کاربران.
* برخلاف دو لایه‌ی دیگر، این لایه نه فقط توسط مدیران سیستم، بلکه توسط **کاربران نهایی (end users)** هم نگهداری می‌شود.

**جزوه:**

* managerial = پرتعدادترین و پرتغییرترین
* نگهداری توزیع‌شده‌تر (حتی توسط کاربران)

**تعاریف/توضیحات کوتاه:**

* End-user maintained: کاربران هم اسم/ساختار را تغییر می‌دهند (مثلاً پوشه‌های شخصی).

**Key Points:**

* تغییر زیاد و تعداد بسیار بالا.
* نگهداری توسط کاربران هم انجام می‌شود.

---

## **اسلاید 38 – عنوان: Name Space Distribution / Comparison**
**ترجمه (جدول):**

* مقیاس جغرافیایی شبکه: Global=Worldwide | Administrational=Organization | Managerial=Department
* تعداد کل گره‌ها: Global=Few | Administrational=Many | Managerial=Vast numbers
* سرعت پاسخ به lookup: Global=Seconds | Administrational=Milliseconds | Managerial=Immediate
* انتشار به‌روزرسانی (Update propagation): Global=Lazy | Administrational=Immediate | Managerial=Immediate
* تعداد replica: Global=Many | Administrational=None or few | Managerial=None
* caching سمت کلاینت؟ Global=Yes | Administrational=Yes | Managerial=Sometimes

**جزوه:**

* بالا (global): کندتر ولی پایدار و heavily replicated
* پایین (managerial): خیلی سریع، بدون replication، تغییرات زیاد

**تعاریف/توضیحات کوتاه:**

* **Lazy propagation**: انتشار با تأخیر/غیرفوری.

**Key Points:**

* تفاوت لایه‌ها در scale، سرعت، و سیاست update/replica.
* global معمولاً replication زیاد و update کند دارد.

---

## **اسلاید 39 – عنوان: Implementation of Name Resolution**
**ترجمه:**

* هر کلاینت به یک **local name resolver** دسترسی دارد که مسئول انجام فرایند name resolution است.
* فرض کنید نام مسیر مطلق (absolute path name) زیر باید resolve شود:
  ⟨nl, VU, CS, ftp, pub, globe, index.html⟩
* با نمایش URL این نام معادل است با:
  `ftp://ftp.cs.vu.nl/pub/globe/index.html`
* دو روش برای پیاده‌سازی name resolution:

  * **Iterative name resolution**
  * **Recursive name resolution**

**جزوه:**

* resolver محلی نقطه شروع درخواست‌هاست.
* دو سبک اجرای resolve: iterative (رفت‌وبرگشت مرحله‌ای) و recursive (زنجیره‌ای بین سرورها).

**تعاریف/توضیحات کوتاه:**

* **Name resolver**: مولفه‌ای که نام را به مقصد ترجمه می‌کند.

**Key Points:**

* resolver محلی مسئول resolve است.
* دو روش اصلی: iterative و recursive.

---

## **اسلاید 40 – عنوان: Iterative name resolution**
**ترجمه:**

* در روش iterative، resolver نام کامل را به **root name server** می‌دهد.
* فرض می‌شود آدرس root server معلوم است.
* root server تا جایی که بتواند نام مسیر را resolve می‌کند و نتیجه را به کلاینت برمی‌گرداند. (کلاینت مرحله‌به‌مرحله ادامه می‌دهد.)

**جزوه:**

* الگو: Client ↔ Root ↔ … (client خودش با سرورهای بعدی تماس می‌گیرد)
* مزیت: بار کمتر روی سرورها (سرورها کل فرایند را کامل نمی‌کنند)

**تعاریف/توضیحات کوتاه:**

* **Iterative**: هر سرور «راهنمای مرحله بعد» را می‌دهد، ادامه با کلاینت است.

**Key Points:**

* سرور نتیجه‌ی میانی را برمی‌گرداند، کلاینت ادامه می‌دهد.
* بار محاسباتی/مدیریتی روی سرور کمتر است.

---

## **اسلاید 41 – عنوان: Recursive name resolution**
**ترجمه:**

* در روش recursive، به‌جای اینکه هر نتیجه‌ی میانی به resolver کلاینت برگردد، **name server** نتیجه را به **name server بعدی** که پیدا می‌کند پاس می‌دهد.

**جزوه:**

* الگو: Client → Root → Server1 → Server2 → … → پاسخ نهایی → Client
* سرورها زنجیره‌وار کار را جلو می‌برند.

**تعاریف/توضیحات کوتاه:**

* **Recursive**: سرور، مسئول ادامه‌ی resolve در مراحل بعدی هم هست.

**Key Points:**

* انتقال مرحله‌ای بین سرورها انجام می‌شود.
* کلاینت درگیر تماس‌های متعدد با سرورها نیست.

---

## **اسلاید 42 – عنوان: Recursive name resolution (Drawback & Advantages)**
**ترجمه:**
**عیب (Drawback):**

* عیب اصلی recursive این است که **بار عملکردی بیشتری** روی هر name server می‌گذارد.
* عملاً یک name server باید resolve کامل یک path name را انجام دهد (هرچند با همکاری دیگر سرورها).
* این بار اضافی آن‌قدر زیاد است که name serverهای لایه‌ی global معمولاً فقط iterative را پشتیبانی می‌کنند.

**مزایا (Advantages):**

* مزیت اول: **cache کردن نتایج (caching results)** نسبت به iterative مؤثرتر است.
* مزیت دوم: **هزینه‌های ارتباطی (communication costs)** ممکن است کاهش یابد.

**جزوه:**

* Trade-off:

  * Recursive: راحت‌تر برای کلاینت + caching بهتر، ولی فشار روی سرور
  * Iterative: فشار کمتر روی سرورها، ولی کلاینت رفت‌وبرگشت بیشتری دارد

**تعاریف/توضیحات کوتاه:**

* **Caching**: ذخیره‌ی نتایج resolve برای پاسخ سریع‌تر در دفعات بعد.

**Key Points:**

* Recursive بار بیشتری روی سرورها می‌گذارد.
* caching بهتر و ارتباطات ممکن است کمتر شود.
* لایه‌ی global معمولاً iterative است.

---

## **اسلاید 43 – عنوان: Attribute-based Naming**
**ترجمه:**

* نام‌های flat و structured معمولاً یک روش **یکتا (unique)** و **مستقل از مکان (location-independent)** برای اشاره به موجودیت‌ها فراهم می‌کنند.
* با زیادشدن اطلاعات، جست‌وجوی مؤثر مهم می‌شود: موجودیت را با زوج‌های **(attribute, value)** توصیف می‌کنیم که به آن **attribute-based** می‌گویند.
* هر attribute چیزی درباره‌ی موجودیت می‌گوید.
* با مشخص کردن اینکه یک attribute چه مقدارهایی داشته باشد، کاربر مجموعه‌ی موجودیت‌های مورد علاقه‌اش را محدود می‌کند.
* سیستم‌های attribute-based را **directory services** هم می‌نامند.
* در directory services، موجودیت‌ها یک مجموعه attribute مرتبط دارند که برای جست‌وجو استفاده می‌شود.

**جزوه:**

* تفاوت با نام‌گذاری معمولی: به‌جای “اسم دقیق”، با “ویژگی‌ها” سرچ می‌کنیم.
* مثال ذهنی: (type=printer, color=true, building=A) → همه چاپگرهای رنگی ساختمان A

**تعاریف/توضیحات کوتاه:**

* **Attribute-based naming**: یافتن/نام‌گذاری بر اساس ویژگی‌ها (نه فقط یک نام ثابت).
* **Directory service**: سرویس فهرست راهنما برای جست‌وجوی موجودیت‌ها.

**Key Points:**

* توصیف با (attribute, value).
* برای search و discovery مناسب است.
* همان directory services.

---

## **اسلاید 44 – عنوان: End of Chapter 4**
**ترجمه:** پایان فصل ۴

**جزوه:**

* فصل ۴ تمام شد: روش‌های نام‌گذاری و مکان‌یابی (forwarding pointers، home-based، DHT، hierarchical، structured naming و resolution).

**تعاریف/توضیحات کوتاه:** —

**Key Points:**

* پایان فصل ۴.

----

# **فصل ۵ (Synchronization)**

---

## **اسلاید 1 – عنوان: Chapter 5: Synchronization**

**ترجمه:** فصل ۵: همگام‌سازی (Synchronization)

**جزوه:**

* این فصل درباره‌ی «همگام‌سازی» در سیستم‌های توزیع‌شده است؛ یعنی چگونه زمان/رویدادها/نقش‌های ویژه و دسترسی به منابع مشترک را هماهنگ کنیم.

**تعاریف/توضیحات کوتاه:**

* همگام‌سازی (Synchronization): هماهنگ‌کردن رفتار اجزای مستقل (فرآیندها/ماشین‌ها) برای رسیدن به یک نتیجه‌ی درست.

**Key Points:**

* شروع فصل ۵: Synchronization
* محورهای اصلی: زمان، ترتیب رویدادها، انتخاب هماهنگ‌کننده، و Mutual Exclusion

---

## **اسلاید 2 – عنوان: Contents**

**ترجمه:** سرفصل‌ها (Contents)

* همگام‌سازی ساعت (Clock Synchronization)
* ساعت‌های منطقی (Logical Clocks)
* حالت سراسری (Global State)
* الگوریتم‌های انتخاب (Election Algorithms)
  -排‌همزمانی متقابل (Mutual Exclusion)
* تراکنش توزیع‌شده (Distributed Transaction)

**جزوه:**

* این فصل چند بخش دارد: از «زمان و ساعت‌ها» شروع می‌کند، بعد به «ترتیب رویدادها»، «انتخاب coordinator»، و «کنترل دسترسی به منابع مشترک» می‌رسد.

**تعاریف/توضیحات کوتاه:**

* حالت سراسری (Global State): تصویری سازگار از وضعیت کل سیستم توزیع‌شده در یک «لحظه‌ی منطقی».

**Key Points:**

* ۶ موضوع کلیدی فصل مشخص شد
* مسیر درس از “زمان” تا “تراکنش توزیع‌شده” پیش می‌رود

---

## **اسلاید 3 – عنوان: Clock Synchronization**

**ترجمه:**
در یک سیستم متمرکز (Centralized System)، زمان مبهم نیست. وقتی یک فرآیند بخواهد زمان را بداند، یک فراخوانی سیستمی (System Call) انجام می‌دهد و کرنل (Kernel) زمان را می‌گوید.
اگر فرآیند A زمان را بپرسد و کمی بعد فرآیند B بپرسد، مقدار زمانی که B می‌گیرد بزرگ‌تر (یا نهایتاً برابر) مقدار A است؛ قطعاً کوچک‌تر نخواهد بود.
در سیستم توزیع‌شده (Distributed System)، رسیدن به توافق روی زمان ساده نیست؛ و وقتی توافق سراسری وجود نداشته باشد، سؤال این است: آیا می‌توان همه‌ی ساعت‌ها را در سیستم توزیع‌شده همگام کرد؟
(شکل ۱: وقتی هر ماشین ساعت خودش را دارد، ممکن است رویدادی که بعدتر رخ داده، زمان زودتری به آن نسبت داده شود.)

**جزوه:**

* در سیستم متمرکز: **یک مرجع زمان واحد** داریم → ترتیب زمانی واضح‌تر است.
* در سیستم توزیع‌شده: هر ماشین ساعت خودش را دارد → امکان **اختلاف زمان** و **ثبت زمان اشتباه نسبت به ترتیب واقعی**.
* مشکل اصلی: «توافق روی زمان» (Time Agreement) و «ترتیب رویدادها» (Event Ordering).

**تعاریف/توضیحات کوتاه:**

* توافق روی زمان: اینکه همه‌ی نودها تقریباً یک زمان مشترک داشته باشند یا بتوانند اختلاف را مدیریت کنند.

**Key Points:**

* زمان در centralized واضح است، در distributed مبهم/چالش‌دار
* ممکن است ترتیب واقعی رویدادها با timestampها ناسازگار شود
* پرسش کلیدی: آیا همگام‌سازی کامل ممکن است؟

---

## **اسلاید 4 – عنوان: Clock Synchronization – Physical Clocks**

**ترجمه:**
ساعت/تایمر کامپیوتر معمولاً یک کریستال کوارتز (Quartz Crystal) دقیق است. وقتی تحت کشش نگه داشته شود، با فرکانس مشخصی نوسان می‌کند.
برای هر کریستال معمولاً دو ثبات (Register) داریم: یک شمارنده (Counter) و یک ثبات نگهدارنده (Holding Register).
هر نوسان کریستال، شمارنده را یکی کم می‌کند. وقتی شمارنده به صفر برسد، یک وقفه (Interrupt) ایجاد می‌شود و شمارنده دوباره از holding register بارگذاری (Reload) می‌شود.
اما در سیستم توزیع‌شده، تضمین اینکه کریستالِ کامپیوترهای مختلف دقیقاً با یک فرکانس کار کنند، غیرممکن است.

**جزوه:**

* مبنای ساعت فیزیکی: نوسان کوارتز → شمارنده/وقفه → ساخت مفهوم «زمان سیستم».
* مسئله‌ی توزیع‌شده: **فرکانس‌ها دقیقاً برابر نیستند** → ساعت‌ها کم‌کم از هم فاصله می‌گیرند.

**تعاریف/توضیحات کوتاه:**

* وقفه (Interrupt): سیگنالی برای قطع جریان عادی CPU و اجرای handler (مثلاً برای به‌روزرسانی زمان).

**Key Points:**

* ساعت فیزیکی = کوارتز + counter/interrupt
* در distributed، فرکانس همه یکی نیست → اختلاف ساعت اجتناب‌ناپذیر

---

## **اسلاید 5 – عنوان: Clock Synchronization – Physical Clocks**

**ترجمه:**
وقتی سیستم n کامپیوتر دارد، هر n کریستال با نرخ کمی متفاوت کار می‌کند، در نتیجه ساعت‌های نرم‌افزاری (Software Clocks) کم‌کم از هم خارج می‌شوند و هنگام خواندن، مقدارهای متفاوتی می‌دهند. این اختلاف زمانی «کجی ساعت» (Clock Skew) نام دارد.
در برخی سیستم‌ها (مثل سیستم‌های بی‌درنگ/Real-Time Systems)، زمان واقعی مهم است؛ در این حالت به ساعت‌های فیزیکی خارجی (External Physical Clocks) نیاز داریم.
به دلایل کارایی و افزونگی (Efficiency & Redundancy)، معمولاً داشتن چند ساعت فیزیکی مطلوب است، که دو مشکل ایجاد می‌کند:

1. چطور آن‌ها را با ساعت‌های دنیای واقعی همگام کنیم؟ (Real World Clocks)
2. چطور ساعت‌ها را با هم همگام کنیم؟ (Clocks with Each Other)

**جزوه:**

* Clock Skew = اختلاف زمان گزارش‌شده بین ماشین‌ها.
* اگر «زمان واقعی» مهم باشد (Real-Time)، باید به مرجع بیرونی هم نگاه کنیم.
* دو نوع همگام‌سازی:

  * با زمان واقعی (External/Real Time)
  * بین خود ماشین‌ها (Internal Synchronization)

**تعاریف/توضیحات کوتاه:**

* Clock Skew: اختلاف مقدار ساعت بین دو نود در یک لحظه.

**Key Points:**

* اختلاف نرخ کریستال‌ها → skew
* Real-time نیازمند ساعت فیزیکی/مرجع بیرونی
* دو مسئله: sync با دنیای واقعی و sync بین نودها

---

## **اسلاید 6 – عنوان: The Berkeley Algorithm**

**ترجمه:**
در این روش، سرور زمان (در واقع یک دیمن زمان / Time Daemon) فعال است و هر از گاهی همه‌ی ماشین‌ها را poll می‌کند تا بپرسد آنجا ساعت چند است.
بر اساس پاسخ‌ها، یک زمان میانگین (Average Time) محاسبه می‌کند و به بقیه می‌گوید ساعتشان را جلو ببرند یا آن را آهسته کنند تا اصلاح مشخصی اعمال شود.
(شکل ۲: (a) دیمن زمان از بقیه مقدار ساعت را می‌پرسد. (b) ماشین‌ها پاسخ می‌دهند. (c) دیمن می‌گوید هرکدام چطور ساعتشان را تنظیم کنند.)

**جزوه:**

* ایده: به جای اتکا به یک ساعت «کاملاً دقیق»، یک coordinator زمان می‌گیرد و **میانگین‌گیری** می‌کند.
* خروجی: دستور تنظیم ساعت برای هر نود (جلو بردن یا کند کردن).

**تعاریف/توضیحات کوتاه:**

* Time Daemon: سرویس/فرآیندی که کار همگام‌سازی زمان را انجام می‌دهد.
* Polling: پرس‌وجوی دوره‌ای از نودها.

**Key Points:**

* Berkeley = poll همه + محاسبه میانگین + اعمال اصلاح
* ممکن است به جای “jump”، ساعت را “slow down” کند

---

## **اسلاید 7 – عنوان: Logical Clocks**

**ترجمه:**
برای بسیاری از کاربردها کافی است که همه‌ی ماشین‌ها روی یک زمان مشترک توافق داشته باشند؛ لازم نیست این زمان دقیقاً با زمان واقعی (مثلاً اعلام رادیو) یکی باشد.
برای این دسته از الگوریتم‌ها، «سازگاری داخلی ساعت‌ها» مهم است نه نزدیک بودن به زمان واقعی. به همین دلیل معمولاً از اصطلاح «ساعت منطقی» (Logical Clock) استفاده می‌شود.

**جزوه:**

* در خیلی از مسائل توزیع‌شده، مهم‌ترین چیز: **ترتیب رویدادها** است، نه ساعت واقعی.
* Logical Clock کمک می‌کند رویدادها را «سازگار و قابل‌مقایسه» زمان‌گذاری کنیم.

**تعاریف/توضیحات کوتاه:**

* Logical Clock: شمارنده/زمانی که فقط برای نظم‌دهی رویدادها استفاده می‌شود، نه نمایش زمان واقعی.

**Key Points:**

* لازم نیست زمان با real time یکی باشد
* سازگاری داخلی مهم‌تر از دقت واقعی است
* ورود به بحث Logical Clocks

---

## **اسلاید 8 – عنوان: Lamport's Logical Clocks**

**ترجمه:**
لامپورت (Lamport) نشان داد که هرچند همگام‌سازی ساعت ممکن است، اما لازم نیست «مطلق» (Absolute) باشد:

* اگر دو فرآیند با هم تعامل (Interact) نداشته باشند، لازم نیست ساعتشان همگام باشد؛ چون عدم همگامی قابل مشاهده نیست و مشکل ایجاد نمی‌کند.
* معمولاً مهم این نیست که همه دقیقاً توافق کنند ساعت چند است؛ مهم این است که روی «ترتیب رخداد رویدادها» (Order of Events) توافق کنند.
  (الگوریتم لامپورت، ساعت‌های منطقی را همگام می‌کند.)

**جزوه:**

* تعامل ندارند → اختلاف ساعت مهم نیست.
* هدف اصلی: **ترتیب (Ordering)** نه زمان واقعی (Exact Time).
* Lamport: راه‌حل برای time-stamping منطقی.

**تعاریف/توضیحات کوتاه:**

* Absolute synchronization: اینکه همه دقیقاً زمان یکسان داشته باشند (در distributed معمولاً غیرضروری/سخت).

**Key Points:**

* همگام‌سازی لازم نیست مطلق باشد
* تمرکز روی order رویدادها
* Lamport → logical clocks

---

## **اسلاید 9 – عنوان: Lamport's timestamps**

**ترجمه:**
برای همگام‌سازی ساعت‌های منطقی، لامپورت رابطه‌ای به نام «قبل-از» (Happens-Before) تعریف کرد:
عبارت (a → b) یعنی «a قبل از b رخ می‌دهد» و یعنی همه‌ی فرآیندها توافق دارند ابتدا رویداد a رخ می‌دهد و سپس رویداد b.
این رابطه به طور مستقیم در دو حالت دیده می‌شود:

1. اگر a و b رویدادهای یک فرآیند باشند و a قبل از b رخ دهد، آنگاه (a → b) درست است.
2. اگر a ارسال یک پیام و b دریافت همان پیام باشد، آنگاه (a → b) درست است؛ چون پیام نمی‌تواند قبل از ارسال دریافت شود (رسیدن پیام زمان مثبتِ غیرصفر می‌خواهد).

**جزوه:**

* تعریف کلیدی: Happens-before (→)
* دو منبع ترتیب:

  * ترتیب داخل یک process
  * رابطه ارسال/دریافت پیام

**تعاریف/توضیحات کوتاه:**

* Happens-before (→): رابطه‌ی علی/ترتیبی بین رویدادها در سیستم توزیع‌شده.

**Key Points:**

* (a → b) یعنی a قبل از b
* داخل یک process و پیام‌رسانی، ترتیب را تعیین می‌کند
* پایه‌ی timestampهای لامپورت

---

## **اسلاید 10 – عنوان: Lamport's timestamps**

**ترجمه:**
رابطه happens-before یک رابطه‌ی تعدی (Transitive) است؛ پس اگر (a → b) و (b → c)، آنگاه (a → c).
اگر دو رویداد x و y در فرآیندهای متفاوت رخ دهند و پیام ردوبدل نکنند، نه (x → y) درست است و نه (y → x). این رویدادها «همزمان/هم‌روند» (Concurrent) هستند؛ یعنی نمی‌توان گفت کدام اول رخ داده است.
همچنین:
اگر (a → b) آنگاه باید C(a) < C(b).
و زمان ساعت C باید همیشه رو به جلو (Increasing) برود و هرگز عقب نرود (Decreasing).

**جزوه:**

* Transitive بودن (تعدی): پایه‌ی ساخت ترتیب‌های طولانی‌تر.
* Concurrent: وقتی هیچ مسیر پیام/ترتیب وجود ندارد → قابل مقایسه نیستند.
* شرط مهم: نگاشت رویدادها به عدد C طوری باشد که ترتیب (→) را حفظ کند.

**تعاریف/توضیحات کوتاه:**

* Concurrent (هم‌روند): رویدادهایی که ترتیبشان قابل تعیین نیست.

**Key Points:**

* happens-before تعدی است
* رویدادهای بدون پیام = concurrent
* اگر a→b ⇒ C(a)<C(b) و C فقط افزایش می‌یابد

---

## **اسلاید 11 – عنوان: Lamport's algorithm**

**ترجمه:**
راه‌حل لامپورت مستقیماً از رابطه happens-before نتیجه می‌شود.
مثال: سه فرآیند را در شکل در نظر بگیرید. این فرآیندها روی ماشین‌های متفاوت هستند، هرکدام ساعت خودشان را دارند و با سرعت خودشان کار می‌کنند.
طبق شکل، وقتی ساعت در فرآیند P1 شش تیک (6 times) زده، در P2 هشت تیک (8 times) و در P3 ده تیک (10 times) زده است. هر ساعت با نرخ ثابت کار می‌کند، اما نرخ‌ها به خاطر تفاوت کریستال‌ها متفاوت‌اند.

**جزوه:**

* قبل از اعمال الگوریتم منطقی، ساعت‌های فیزیکی می‌توانند سرعت‌های متفاوت داشته باشند.
* این مثال زمینه‌سازی می‌کند که چرا باید timestamp منطقی داشته باشیم.

**تعاریف/توضیحات کوتاه:**

* Tick: واحد پیشروی ساعت/شمارنده.

**Key Points:**

* ساعت‌های فیزیکی نرخ‌های متفاوت دارند
* مثال سه فرآیند برای نشان دادن اختلاف سرعت ساعت‌ها

---

## **اسلاید 12 – عنوان: Lamport's algorithm**

**ترجمه:**
هر پیام، «زمان ارسال» (Sending Time) را طبق ساعت فرستنده حمل می‌کند. وقتی پیام برسد و ساعت گیرنده مقداری قبل از زمان ارسال پیام را نشان دهد، گیرنده ساعتش را جلو می‌کشد (Fast Forward) تا «یک واحد بیشتر از زمان ارسال» شود.

**جزوه:**

* پیام‌ها timestamp دارند (ts).
* قانون دریافت: اگر گیرنده عقب‌تر است، خودش را جلو می‌کشد تا ترتیب علی حفظ شود.

**تعاریف/توضیحات کوتاه:**

* Fast forward: جهش رو به جلو برای جلوگیری از نقض ترتیب.

**Key Points:**

* هر پیام timestamp ارسال را حمل می‌کند
* گیرنده اگر عقب باشد: clock = ts+1
* هدف: حفظ ترتیب happens-before

---

## **اسلاید 13 – عنوان: Lamport's algorithm**

**ترجمه:**
برای پیاده‌سازی ساعت‌های منطقی لامپورت، هر فرآیند Pi یک شمارنده محلی Ci نگه می‌دارد. این شمارنده‌ها این‌گونه به‌روزرسانی می‌شوند:

* قبل از اجرای هر رویداد (مثل ارسال پیام، تحویل پیام به برنامه، یا رویداد داخلی)، Pi انجام می‌دهد: **Ci ← Ci + 1**
* وقتی Pi پیامی m برای Pj می‌فرستد، برچسب زمانی پیام را برابر Ci قرار می‌دهد: **ts(m) = Ci** (بعد از افزایش مرحله قبل)
* هنگام دریافت پیام m، فرآیند Pj شمارنده‌اش را تنظیم می‌کند: **Cj ← max{Cj, ts(m)}** سپس مرحله اول را اجرا می‌کند و پیام را به برنامه تحویل می‌دهد.

**جزوه:**

* سه قانون اصلی Lamport clock:

  1. قبل هر event: ++Ci
  2. ارسال: ts(m)=Ci
  3. دریافت: Cj=max(Cj,ts(m)) سپس ++ و deliver

**تعاریف/توضیحات کوتاه:**

* ts(m) (Timestamp): برچسب زمانی پیام.

**Key Points:**

* Ci محلی است و با رویدادها افزایش می‌یابد
* دریافت پیام باعث هم‌تراز شدن با timestamp می‌شود
* قانون max + increment ترتیب را حفظ می‌کند

---

## **اسلاید 14 – عنوان: Lamport's algorithm**

**ترجمه:**
با timestampهای لامپورت می‌توان به همه رویدادها در سیستم توزیع‌شده زمان داد، با شرایط زیر:

1. اگر a قبل از b در همان فرآیند رخ دهد، **C(a) < C(b)**
2. اگر a ارسال پیام و b دریافت آن باشد، **C(a) < C(b)**
3. برای هر دو رویداد متمایز a و b، باید **C(a) ≠ C(b)**

**جزوه:**

* شرط 1 و 2: حفظ happens-before.
* شرط 3: جلوگیری از مساوی شدن timestamp رویدادهای مختلف (برای مرتب‌سازی دقیق).

**تعاریف/توضیحات کوتاه:**

* Distinct events: رویدادهای متفاوت/غیر یکسان.

**Key Points:**

* a→b ⇒ C(a)<C(b)
* ارسال قبل از دریافت است
* timestamps یکتا برای رویدادهای متمایز

---

## **اسلاید 15 – عنوان: Election Algorithms**

**ترجمه:**
بسیاری از الگوریتم‌های توزیع‌شده نیاز دارند یک فرآیند نقش ویژه‌ای داشته باشد: هماهنگ‌کننده (Coordinator)، آغازگر (Initiator) یا نقش خاص دیگر.
مهم نیست کدام فرآیند این مسئولیت را بگیرد، اما یکی باید آن را انجام دهد.
اگر همه‌ی فرآیندها کاملاً یکسان باشند و ویژگی تمایزدهنده نداشته باشند، راهی برای انتخاب یکی به عنوان ویژه وجود ندارد.

**جزوه:**

* ضرورت election: برای داشتن «رهبر/هماهنگ‌کننده» در کارهای مشترک.
* شرط لازم: فرآیندها باید قابل تمایز باشند (ID/شماره یکتا).

**تعاریف/توضیحات کوتاه:**

* Coordinator: فرآیندی که تصمیم‌گیری/هماهنگی مرکزی را انجام می‌دهد.

**Key Points:**

* بعضی الگوریتم‌ها نیاز به coordinator دارند
* انتخاب بدون ویژگی تمایزدهنده ممکن نیست

---

## **اسلاید 16 – عنوان: Election Algorithms**

**ترجمه:**
فرض می‌کنیم هر فرآیند یک شماره یکتا دارد (Unique Number)، مثلاً آدرس شبکه‌اش (Network Address).
به طور کلی الگوریتم‌های انتخاب سعی می‌کنند فرآیند با «بالاترین شماره» را پیدا کنند و آن را coordinator کنند.
الگوریتم‌ها در روش پیدا کردن متفاوت‌اند:

* Bully Algorithm
* Ring Algorithm

**جزوه:**

* معیار رایج: max(ID) → leader
* تفاوت الگوریتم‌ها: پیام‌رسانی/پیچیدگی/نحوه تشخیص خرابی.

**تعاریف/توضیحات کوتاه:**

* Unique ID: شناسه یکتای فرآیند برای مقایسه و انتخاب.

**Key Points:**

* هر فرآیند ID یکتا دارد
* معمولاً بالاترین ID رهبر می‌شود
* دو الگوریتم مهم: Bully و Ring

---

## **اسلاید 17 – عنوان: The Bully Algorithm**

**ترجمه:**
وقتی هر فرآیندی متوجه شود coordinator دیگر به درخواست‌ها پاسخ نمی‌دهد، یک انتخاب (Election) را آغاز می‌کند.
فرآیند P این‌گونه انتخاب را انجام می‌دهد:

1. P یک پیام ELECTION به همه فرآیندهای با شماره بالاتر می‌فرستد.
2. اگر هیچ‌کس پاسخ ندهد، P برنده می‌شود و coordinator می‌گردد.
3. اگر یکی از بالادستی‌ها پاسخ بدهد، او ادامه می‌دهد و P کارش تمام است.

**جزوه:**

* ایده: اگر بالادستی زنده باشد، حق رهبری با اوست.
* P فقط “ping” می‌زند به بالاترها؛ اگر جواب نیاید → خودش رهبر.

**تعاریف/توضیحات کوتاه:**

* ELECTION message: پیام شروع فرآیند انتخاب رهبر.

**Key Points:**

* تشخیص خرابی coordinator → شروع election
* پیام به IDهای بالاتر
* نبود پاسخ ⇒ پیروزی فرستنده

---

## **اسلاید 18 – عنوان: The Bully Algorithm**

**ترجمه:**
هر لحظه ممکن است یک فرآیند پیام ELECTION از همکاران با شماره پایین‌تر دریافت کند. وقتی این پیام رسید، گیرنده یک پیام OK به فرستنده می‌دهد تا نشان دهد زنده است و کنترل را به دست می‌گیرد.
در نهایت همه کنار می‌کشند جز یکی، و او coordinator جدید است. او با ارسال پیام به همه اعلام می‌کند که از همین لحظه coordinator جدید است.
اگر فرآیندی که قبلاً down بوده دوباره up شود، یک election برگزار می‌کند؛ اگر بالاترین شماره‌ی درحال‌اجرا باشد، برنده می‌شود و نقش coordinator را می‌گیرد. پس «بزرگ‌تر همیشه می‌برد» و نام bully از همین آمده است.

**جزوه:**

* پاسخ OK یعنی “من زنده‌ام و از تو قوی‌تر/بالاترم”.
* اگر نود با ID بالاتر برگردد، ممکن است رهبر را عوض کند.

**تعاریف/توضیحات کوتاه:**

* Bully: فرآیند با ID بالاتر، بقیه را کنار می‌زند و رهبر می‌شود.

**Key Points:**

* دریافت ELECTION از پایین‌تر ⇒ ارسال OK
* در نهایت highest-ID رهبر می‌شود
* بازگشت نود قوی‌تر می‌تواند رهبر را عوض کند

---

## **اسلاید 19 – عنوان: The Bully Algorithm**

**ترجمه:**
(شکل) نمایش مرحله‌به‌مرحله‌ی Bully Algorithm: وقتی coordinator قبلی crash کرده، یک فرآیند (مثلاً با شماره 4) به بالاتری‌ها پیام **Election** می‌دهد؛ بالاتری‌ها **OK** می‌دهند؛ سپس یک فرآیند بالاتر (مثلاً 6) election را ادامه می‌دهد و در پایان پیام **Coordinate/Coordinator** به همه ارسال می‌کند تا رهبر جدید اعلام شود.

**جزوه:**

* جریان کلی شکل:

  * تشخیص crash رهبر قبلی
  * ارسال Election به IDهای بالاتر
  * پاسخ OK از بالاترها
  * برنده (بالاترینِ زنده) پیام Coordinator را broadcast می‌کند

**تعاریف/توضیحات کوتاه:**

* Broadcast announcement: پیام اعلام رهبر جدید برای همه.

**Key Points:**

* Election از پایین به بالا شروع می‌شود
* OK یعنی «من هستم و ادامه می‌دهم»
* highest alive ⇒ coordinator و اعلام به همه

---

## **اسلاید 20 – عنوان: A Ring Algorithm**

**ترجمه:**
این الگوریتم بر اساس استفاده از یک حلقه (Ring) است.
فرض می‌کنیم فرآیندها به صورت فیزیکی یا منطقی مرتب شده‌اند (Physically/Logically Ordered)، طوری که هر فرآیند جانشین خود (Successor) را می‌شناسد.
وقتی هر فرآیند بفهمد coordinator کار نمی‌کند، یک پیام **ELECTION** می‌سازد که شماره‌ی خودش را دارد و آن را به جانشینش می‌فرستد.
اگر جانشین down باشد، فرستنده از او می‌گذرد و به عضو بعدی در حلقه می‌رود تا یک فرآیند فعال پیدا شود.
در هر گام، فرستنده شماره‌ی خودش را به لیست داخل پیام اضافه می‌کند و عملاً خودش را کاندید coordinator می‌کند.

**جزوه:**

* ساختار ring: هر نود فقط successor را می‌داند.
* پیام election دور می‌چرخد و لیست کاندیدها جمع می‌شود.
* تحمل خرابی: skip کردن نودهای down.

**تعاریف/توضیحات کوتاه:**

* Successor: نود بعدی در حلقه (Ring).

**Key Points:**

* Ring-based election
* ELECTION message دور حلقه می‌چرخد
* نودهای down skip می‌شوند
* لیست کاندیدها در پیام جمع می‌شود

---

## **اسلاید 21 – عنوان: A Ring Algorithm**

**ترجمه:**
در نهایت پیام به فرآیندی که همه‌چیز را شروع کرده بود برمی‌گردد.
آن فرآیند وقتی این رویداد را تشخیص می‌دهد که پیام ورودی شامل شماره خودش باشد.
در آن نقطه نوع پیام به **COORDINATOR** تغییر می‌کند و دوباره یک دور می‌چرخد تا به همه اعلام کند coordinator کیست (عضو با بالاترین شماره) و اعضای حلقه‌ی جدید چه کسانی هستند.
وقتی این پیام یک دور کامل زد، حذف می‌شود و همه به کار برمی‌گردند.

**جزوه:**

* پایان election: برگشت پیام به initiator.
* سپس پیام Coordinator برای اعلام رهبر جدید دور می‌زند.

**تعاریف/توضیحات کوتاه:**

* Initiator: فرآیندی که election را شروع می‌کند.

**Key Points:**

* برگشت پیام = تشخیص پایان جمع‌آوری
* پیام COORDINATOR رهبر (max ID) را اعلام می‌کند
* بعد از یک دور، سیستم به حالت عادی برمی‌گردد

---

## **اسلاید 22 – عنوان: A Ring Algorithm**

**ترجمه:**
(شکل ۳) نمونه‌ی اجرای election در حلقه: coordinator قبلی crash کرده، پیام ELECTION از یک نود شروع می‌شود، برخی نودها پاسخ نمی‌دهند (No response) و پیام از آن‌ها عبور می‌کند، و در نهایت لیست شرکت‌کنندگان/کاندیدها در پیام شکل می‌گیرد و رهبر جدید تعیین می‌شود.

**جزوه:**

* شکل نشان می‌دهد چگونه پیام دور می‌چرخد و در مسیر، لیست IDها ساخته می‌شود.
* skip کردن نود crash شده در عمل دیده می‌شود.

**تعاریف/توضیحات کوتاه:**

* Ring traversal: گردش پیام در حلقه.

**Key Points:**

* نمایش تصویری skip خرابی‌ها
* جمع شدن لیست IDها در پیام
* تعیین رهبر با بالاترین ID

---

## **اسلاید 23 – عنوان: MUTUAL EXCLUSION**

**ترجمه:**
排‌همزمانی متقابل (Mutual Exclusion)

* الگوریتم متمرکز (Centralized Algorithm)
* الگوریتم توزیع‌شده (Distributed Algorithm)
* الگوریتم حلقه توکنی (Token Ring Algorithm)

**جزوه:**

* ورود به مبحث مهم: کنترل دسترسی به «منابع مشترک» (Shared Resource) به‌طوری‌که همزمان فقط یک فرآیند وارد بخش بحرانی شود.

**تعاریف/توضیحات کوتاه:**

* Mutual Exclusion: تضمین اینکه در هر لحظه فقط یک فرآیند از منبع/بخش بحرانی استفاده کند.

**Key Points:**

* شروع بخش Mutual Exclusion
* سه رویکرد: متمرکز، توزیع‌شده، توکن‌رینگ

---

## **اسلاید 24 – عنوان: A Centralized Algorithm**

**ترجمه:**
یک فرآیند به عنوان هماهنگ‌کننده (Coordinator) انتخاب می‌شود.
هر زمان فرآیندی بخواهد به یک منبع مشترک (Shared Resource) دسترسی پیدا کند، یک پیام درخواست (Request Message) به coordinator می‌فرستد و می‌گوید کدام منبع را می‌خواهد و اجازه می‌خواهد.
اگر هیچ فرآیند دیگری در حال استفاده از آن منبع نباشد، coordinator یک پاسخ (Reply) می‌فرستد و اجازه می‌دهد (Granting Permission). وقتی پاسخ برسد، فرآیند درخواست‌دهنده می‌تواند ادامه دهد.

**جزوه:**

* ایده‌ی مرکزی: یک coordinator مثل “قفل مرکزی” عمل می‌کند.
* اگر resource آزاد بود ⇒ grant.

**تعاریف/توضیحات کوتاه:**

* Grant: پیام اجازه ورود/استفاده از منبع.

**Key Points:**

* coordinator مرجع صدور اجازه است
* درخواست → بررسی → grant اگر آزاد باشد
* ساده ولی وابسته به coordinator

---

## **اسلاید 25 – عنوان: A Centralized Algorithm**

**ترجمه:**
حالا فرض کنید یک فرآیند دیگر هم اجازه‌ی دسترسی به منبع را بخواهد.
coordinator می‌داند فرآیند دیگری در حال استفاده از منبع است، پس نمی‌تواند اجازه بدهد.
coordinator به سادگی پاسخ نمی‌دهد و فرآیند ۲ بلوکه می‌شود (Blocked) چون منتظر پاسخ است.
یا می‌تواند پاسخ بدهد: «اجازه رد شد» (Permission Denied).

**جزوه:**

* وقتی resource مشغول است:

  * یا reply ندهیم → blocking
  * یا explicit deny بدهیم
* در عمل معمولاً درخواست‌ها صف (Queue) می‌شوند (در اسلاید بعد توضیح می‌دهد).

**تعاریف/توضیحات کوتاه:**

* Blocked: فرآیند تا دریافت پاسخ/آزاد شدن منبع متوقف می‌ماند.

**Key Points:**

* اگر منبع مشغول باشد ⇒ grant نمی‌شود
* یا silence برای block، یا پاسخ deny
* زمینه برای queue درخواست‌ها

---

## **اسلاید 26 – عنوان: A Centralized Algorithm**

**ترجمه:**
وقتی فرآیند ۱ کارش با منبع تمام شد، پیامی به coordinator می‌فرستد و دسترسی انحصاری (Exclusive Access) را آزاد می‌کند (Releasing).
coordinator اولین مورد را از صف درخواست‌های معوق (Queue of Deferred Requests) برمی‌دارد و برای آن فرآیند پیام grant می‌فرستد.
اگر آن فرآیند هنوز بلوکه باشد، از بلوکه خارج می‌شود (Unblocks) و به منبع دسترسی پیدا می‌کند.

**جزوه:**

* مدیریت صف: درخواست‌های رد/معوق در queue نگه داشته می‌شوند.
* release از طرف دارنده منبع → grant به نفر بعدی.

**تعاریف/توضیحات کوتاه:**

* Deferred Request: درخواستی که فعلاً قابل قبول نیست و به تعویق/صف منتقل می‌شود.

**Key Points:**

* پایان کار ⇒ release به coordinator
* coordinator صف را مدیریت می‌کند
* grant به اولین درخواست معوق

---

## **اسلاید 27 – عنوان: A Centralized Algorithm (الگوریتم متمرکز)**
**ترجمه:**

* در مدل OSI، ارتباطات به هفت سطح/لایه تقسیم می‌شود.
* **شکل ۱۳: یک الگوریتم متمرکز (A Centralized Algorithm)**
* در شکل، «هماهنگ‌کننده/Coordinator» درخواست‌ها (Request) را دریافت می‌کند، به بعضی‌ها پاسخ OK می‌دهد، بعضی درخواست‌ها را در صف (Queue) نگه می‌دارد، و در پایان با پیام Release آزادسازی انجام می‌شود (و گاهی No reply یعنی پاسخی داده نمی‌شود).

**جزوه:**

* **ایده‌ی کلی الگوریتم متمرکز (Centralized Mutual Exclusion):**

  * یک فرآیند مرکزی به نام **Coordinator (هماهنگ‌کننده)** مسئول مدیریت دسترسی به منبع مشترک است.
  * فرآیندها برای ورود به ناحیه بحرانی، **Request** می‌فرستند.
  * Coordinator اگر منبع آزاد باشد **OK/Grant** می‌دهد؛ اگر مشغول باشد درخواست را **صف** می‌کند.
  * پس از پایان کار، فرآیند **Release** می‌فرستد تا نفر بعدی مجاز شود.
* **توضیح تصویر:**

  * نمودار نشان می‌دهد چند فرآیند (۰،۱،۲،۳) به Coordinator پیام می‌دهند، Coordinator برخی را در صف نگه می‌دارد و به یکی اجازه می‌دهد؛ سپس با Release نوبت‌ها جلو می‌رود.

**تعاریف/توضیحات کوتاه:**

* **ناحیه بحرانی (Critical Section):** بخشی از کد که فقط یک فرآیند باید هم‌زمان وارد آن شود.
* **Mutual Exclusion (排除 متقابل):** تضمین اینکه هم‌زمان بیش از یک فرآیند منبع مشترک را استفاده نکند.

**Key Points:**

* Coordinator نقطه‌ی تصمیم‌گیری واحد است.
* صف‌کردن درخواست‌ها ساده‌ترین راه کنترل همزمانی در حالت متمرکز است.
* پیام‌های کلیدی: Request / OK / Release.

---

## **اسلاید 28 – عنوان: A Distributed algorithm (الگوریتم توزیع‌شده)**
**ترجمه:**

* وقتی یک فرآیند می‌خواهد به منبع مشترک دسترسی پیدا کند، پیامی می‌سازد که شامل **نام منبع**، **شماره فرآیند** و **زمان (منطقی) جاری** (current **logical time**) است.
* وقتی یک فرآیند پیام درخواست (request message) را از فرآیند دیگری دریافت می‌کند…
* **الگوریتم توزیع‌شده (A Distributed algorithm)**

**جزوه:**

* **ایده‌ی قفل‌گذاری/مجوزدهی توزیع‌شده (Distributed Mutual Exclusion):**

  * به‌جای Coordinator، خودِ فرآیندها با هم هماهنگ می‌شوند.
  * هر درخواست با **timestamp (برچسب زمانی)** بر اساس **logical clock (ساعت منطقی)** ارسال می‌شود.
* **نقش timestamp:** تعیین تقدم درخواست‌ها برای حل تعارض.

**تعاریف/توضیحات کوتاه:**

* **Logical Time / Logical Clock (زمان/ساعت منطقی):** شمارنده‌ای برای مرتب‌سازی رویدادها در سیستم توزیع‌شده (نه زمان واقعی).

**Key Points:**

* درخواست شامل resource name + process id + logical timestamp است.
* در توزیع‌شده، ترتیب‌دهی با timestamp انجام می‌شود.

---

## **اسلاید 29 – عنوان: Distributed algorithm (الگوریتم توزیع‌شده)**
**ترجمه:**

1. اگر گیرنده نه در حال استفاده از منبع است و نه می‌خواهد از آن استفاده کند، یک پیام **OK** برای فرستنده می‌فرستد.
2. اگر گیرنده همین حالا به منبع دسترسی دارد، اصلاً پاسخ نمی‌دهد؛ در عوض درخواست را **صف** می‌کند.
3. اگر گیرنده هم می‌خواهد منبع را بگیرد ولی هنوز نگرفته، **timestamp** پیام ورودی را با timestamp درخواست خودش مقایسه می‌کند (درخواستی که قبلاً برای همه فرستاده). **کوچک‌تر برنده است.** اگر پیام ورودی timestamp کوچک‌تری داشت، گیرنده OK می‌دهد؛ اگر درخواست خودش timestamp کوچک‌تری داشت، درخواست ورودی را صف می‌کند و چیزی نمی‌فرستد.

**جزوه:**

* این دقیقاً منطق رایج در الگوریتم‌هایی مثل **Ricart–Agrawala** (نام در اسلاید نیامده) است:

  * **اولویت با timestamp کمتر** (قدیمی‌تر)
  * در صورت تعارض، یکی OK می‌گیرد و دیگری در صف می‌ماند.
* **Queue** یعنی درخواست‌های منتظر مجوز.

**تعاریف/توضیحات کوتاه:**

* **Timestamp (برچسب زمانی):** عددی برای مقایسه ترتیب درخواست‌ها.
* **OK (Permission/Grant):** پیام اجازه ورود به منبع.

**Key Points:**

* سه حالت گیرنده: بی‌علاقه → OK، در حال استفاده → صف/بدون پاسخ، علاقه‌مند و منتظر → مقایسه timestamp.
* قانون طلایی: **lowest timestamp wins**.

---

## **اسلاید 30 – عنوان: Distributed algorithm (الگوریتم توزیع‌شده)**
**ترجمه:**

* بعد از ارسال درخواست‌ها برای گرفتن اجازه، یک فرآیند می‌نشیند و منتظر می‌ماند تا همه‌ی بقیه اجازه بدهند.
* به‌محض اینکه همه‌ی مجوزها رسید، می‌تواند وارد شود.
* وقتی کارش تمام شد، به همه‌ی فرآیندهای داخل صف خودش پیام **OK** می‌فرستد و همه‌ی آن‌ها را از صف حذف می‌کند.
* این الگوریتم نسبت به نسخه‌ی متمرکز **کندتر، پیچیده‌تر، گران‌تر و کم‌دوام‌تر/کم‌robust‌تر** است.

**جزوه:**

* **هزینه پیام‌رسانی:** برای ورود باید از همه OK بگیرد ⇒ سربار زیاد.
* **پایان کار:** با ارسال OK به درخواست‌های صف‌شده، نوبت‌ها آزاد می‌شوند.
* **مقایسه با متمرکز:**

  * مزیت توزیع‌شده: حذف Coordinator (نقطه تک‌خرابی)
  * عیب: سربار پیام و پیچیدگی بیشتر

**تعاریف/توضیحات کوتاه:**

* **Robust (مقاوم/تاب‌آور):** سیستم در برابر خرابی‌ها و خطاها بهتر دوام بیاورد.

**Key Points:**

* ورود = دریافت OK از همه.
* خروج = OK دادن به صف خود.
* trade-off: حذف مرکزیت ↔ هزینه/پیچیدگی بیشتر.

---

## **اسلاید 31 – عنوان: Distributed algorithm – Example (مثال)**
**ترجمه:**

* فرآیند ۰ برای همه یک درخواست با timestamp=8 می‌فرستد، هم‌زمان فرآیند ۲ یک درخواست با timestamp=12 می‌فرستد.
* فرآیند ۱ به منبع علاقه ندارد، پس به هر دو **OK** می‌دهد.
* فرآیندهای ۰ و ۲ تعارض را می‌بینند و timestampها را مقایسه می‌کنند.
* فرآیند ۲ می‌بیند باخته، پس با ارسال **OK** به ۰ اجازه می‌دهد.
* فرآیند ۰ درخواست ۲ را برای بعد در صف می‌گذارد و وارد منبع می‌شود (طبق شکل).
* وقتی تمام شد، درخواست ۲ را از صف حذف می‌کند و به ۲ **OK** می‌فرستد تا او وارد شود.

**جزوه:**

* نمونه‌ی کلاسیک «اولویت با timestamp کمتر»: 8 بر 12 مقدم است.
* صف در سمت برنده تشکیل می‌شود تا بعداً به بازنده اجازه بدهد.

**تعاریف/توضیحات کوتاه:**

* **Conflict (تعارض):** دو درخواست هم‌زمان برای یک منبع مشترک.

**Key Points:**

* timestamp=8 جلوتر از 12 است.
* بازنده (P2) OK می‌دهد و منتظر می‌ماند.
* برنده بعد از اتمام، OK را به صف خودش ارسال می‌کند.

---

## **اسلاید 32 – عنوان: Distributed algorithm – Fig 14 (شکل ۱۴)**
**ترجمه:**

* **شکل ۱۴: الگوریتم توزیع‌شده (Distributed Algorithm)**
* نمودار نشان می‌دهد چگونه پیام‌های OK و درخواست‌ها بین فرآیندها رد و بدل می‌شود تا یکی وارد منبع شود و دیگری بعداً وارد شود.

**جزوه:**

* **توضیح تصویر:**

  * حالت‌های (a)، (b)، (c) مراحل قبل/حین/بعد از دسترسی به منبع را نشان می‌دهند.
  * فرآیند برنده وارد منبع می‌شود (**Accesses resource**) و پیام‌های OK بین گره‌ها ردوبدل می‌شود.
  * timestampها (مثل 8 و 12) کنار درخواست‌ها برای تعیین تقدم آمده‌اند.

**تعاریف/توضیحات کوتاه:**

* این شکل، جریان پیام‌ها و صف‌کردن درخواست‌ها را در الگوریتم توزیع‌شده نمایش می‌دهد.

**Key Points:**

* تصویر = نمایش گام‌به‌گام تبادل OK و تقدم timestampها.
* Accesses resource فقط برای یک فرآیند در هر لحظه رخ می‌دهد.

---

## **اسلاید 33 – عنوان: A Token Ring Algorithm (الگوریتم حلقه توکنی)**
**ترجمه:**

* در نرم‌افزار، یک **حلقه منطقی (logical ring)** ساخته می‌شود که در آن به هر فرآیند یک موقعیت در حلقه داده می‌شود.
* موقعیت‌ها می‌توانند بر اساس ترتیب عددی آدرس‌های شبکه یا روش‌های دیگر تعیین شوند.
* وقتی حلقه مقداردهی اولیه می‌شود، به فرآیند ۰ یک **توکن (token)** داده می‌شود.
* توکن در حلقه می‌چرخد.

**جزوه:**

* **ایده:** اجازه دسترسی = داشتن token.
* ساختار ارتباطی: ring overlay (حلقه منطقی روی شبکه واقعی).

**تعاریف/توضیحات کوتاه:**

* **Token (توکن):** یک پیام/شیء منطقی که داشتنش یعنی اجازه ورود به منبع.

**Key Points:**

* ring منطقی ساخته می‌شود.
* token ابتدا دست P0 است و سپس می‌چرخد.

---

## **اسلاید 34 – عنوان: A Token Ring Algorithm (ادامه)**
**ترجمه:**

* وقتی یک فرآیند توکن را از همسایه‌اش می‌گیرد، بررسی می‌کند آیا لازم دارد به منبع مشترک دسترسی پیدا کند یا نه.
* اگر لازم داشت، وارد می‌شود، کارهای لازم را انجام می‌دهد و منبع را آزاد می‌کند.
* بعد از تمام شدن، توکن را در حلقه جلو می‌فرستد.
* اجازه ندارد با همان توکن فوراً دوباره وارد منبع شود.
* بنابراین اگر هیچ‌کس منبع را نخواهد، توکن با سرعت بالا دور حلقه می‌چرخد.

**جزوه:**

* **مزیت:** پیام‌ها ساده و منظم‌اند، نیاز به رأی‌گیری از همه نیست.
* **نکته مهم:** جلوگیری از «انحصار» با ممنوعیت ورود دوباره با همان توکن.

**تعاریف/توضیحات کوتاه:**

* **Fairness (عدالت):** توکن بین همه می‌چرخد ⇒ نوبت‌دهی طبیعی.

**Key Points:**

* داشتن token شرط ورود است.
* ورود دوباره با همان token ممنوع ⇒ جلوگیری از سوءاستفاده.
* در نبود درخواست، token فقط گردش می‌کند.

---

## **اسلاید 35 – عنوان: A Token Ring Algorithm – Fig 15 (شکل ۱۵)**
**ترجمه:**

* **شکل ۱۵: الگوریتم Token Ring**
* تصویر دو حالت (a) و (b) از چرخش توکن و ترتیب گره‌ها (۰ تا ۷) در حلقه را نشان می‌دهد.

**جزوه:**

* **توضیح تصویر:**

  * یک حلقه با چند فرآیند (۰..۷) نمایش داده شده است.
  * حالت‌ها نشان می‌دهند توکن در چه مسیری و با چه ترتیبی بین همسایه‌ها جابه‌جا می‌شود.

**تعاریف/توضیحات کوتاه:**

* token مثل «نوبت» است که از نفر قبلی به نفر بعدی می‌رسد.

**Key Points:**

* شکل = نمایش ترتیب منطقی حلقه و گردش token.
* دسترسی به منبع با توکن کنترل می‌شود.

---

## **اسلاید 36 – عنوان: The Transaction model (مدل تراکنش)**
**ترجمه:**

* تراکنش‌های توزیع‌شده (Distributed transactions)
* طبقه‌بندی تراکنش‌ها (Classification of transactions)

**جزوه:**

* ورود به مبحث **Transaction (تراکنش)** به‌عنوان مدل مهم در سیستم‌های توزیع‌شده/پایگاه‌داده.
* دو محور:

  * تراکنش توزیع‌شده
  * انواع تراکنش‌ها

**تعاریف/توضیحات کوتاه:**

* **Transaction (تراکنش):** مجموعه عملیات که باید «همه یا هیچ» و با تضمین‌های مشخص اجرا شود.

**Key Points:**

* شروع فصل تراکنش‌ها: distributed + classification.

---

## **اسلاید 37 – عنوان: The Transaction model (شرح کلی تراکنش)**
**ترجمه:**

* یک فرآیند اعلام می‌کند که می‌خواهد با یک یا چند فرآیند دیگر یک تراکنش را شروع کند.
* آن‌ها می‌توانند درباره گزینه‌ها مذاکره کنند، موجودیت‌ها را ایجاد/حذف کنند و مدتی عملیات انجام دهند.
* سپس آغازگر اعلام می‌کند که می‌خواهد همه‌ی دیگران کار انجام‌شده تا اینجا را **Commit (متعهد/قطعی)** کنند.
* اگر همه موافق باشند، نتایج دائمی می‌شود.
* اگر یک یا چند فرآیند مخالفت کنند (یا قبل از توافق کرش کنند)، وضعیت دقیقاً به حالت قبل از شروع تراکنش برمی‌گردد.

**جزوه:**

* **چرخه تراکنش:** Begin → عملیات → درخواست Commit → (همه موافق) Commit / (مخالفت یا Crash) Rollback/Abort
* **هدف:** یا همه با هم موفق، یا همه برگردند عقب.

**تعاریف/توضیحات کوتاه:**

* **Commit:** تثبیت دائمی تغییرات.
* **Abort/Rollback:** لغو و بازگردانی به حالت قبل.

**Key Points:**

* توافق جمعی شرط Commit است.
* Crash قبل از توافق می‌تواند باعث Abort شود.
* تراکنش = بازگشت دقیق به قبل در حالت شکست.

---

## **اسلاید 38 – عنوان: The Transaction model – Primitives (دستورات پایه)**
**ترجمه:**

* BEGIN_TRANSACTION: علامت‌زدن شروع تراکنش
* END_TRANSACTION: پایان‌دادن تراکنش و تلاش برای Commit
* ABORT_TRANSACTION: کشتن تراکنش و بازگردانی به مقدار/وضعیت قدیمی
* READ: خواندن داده از فایل/جدول/…
* WRITE: نوشتن داده در فایل/جدول/…
* اشیای ارتباطی سطح پایین (Low level communicative objects) در تراکنش‌ها

**جزوه:**

* **Primitiveها (عملیات پایه):** حداقل API برای پیاده‌سازی تراکنش.
* **نقش END_TRANSACTION:** درخواست Commit (قطعی‌سازی).
* **READ/WRITE:** عملیات داده‌ای که باید تحت کنترل همزمانی و اتمیک‌بودن انجام شوند.

**تعاریف/توضیحات کوتاه:**

* **Primitive:** دستور پایه‌ای که سیستم تراکنشی فراهم می‌کند.

**Key Points:**

* BEGIN/END/ABORT ستون فقرات کنترل تراکنش‌اند.
* READ/WRITE عملیات‌هایی‌اند که باید محافظت شوند.

---

## **اسلاید 39 – عنوان: Features of transactions (ویژگی‌های تراکنش‌ها – ACID)**
**ترجمه:**

* Atomic (اتمی): از دید بیرونی، تراکنش به‌صورت غیرقابل‌تقسیم رخ می‌دهد.
* Consistent (سازگار): تراکنش قوانین/ناوردایی‌های سیستم (system invariants) را نقض نمی‌کند.
* Isolated (ایزوله): تراکنش‌های همزمان در کار هم دخالت نمی‌کنند.
* Durable (مانا/دوام‌دار): بعد از Commit، تغییرات دائمی هستند.
* Atomic: هر تراکنش یا کامل رخ می‌دهد یا اصلاً رخ نمی‌دهد.

**جزوه:**

* **ACID (ای‌سید):** مجموعه تضمین‌های کلاسیک برای تراکنش‌ها.
* **Atomicity** مهم‌ترین پایه‌ی «همه یا هیچ».

**تعاریف/توضیحات کوتاه:**

* **Invariant:** شرطی که همیشه باید درست بماند (مثل: موجودی حساب منفی نشود).

**Key Points:**

* ACID = Atomic + Consistent + Isolated + Durable.
* Atomicity یعنی کامل یا صفر.

---

## **اسلاید 40 – عنوان: Classification of transaction (طبقه‌بندی تراکنش)**
**ترجمه:**

* Flat transaction (تراکنش تخت/ساده)
* Nested transaction (تراکنش تو‌در‌تو)
* Distributed transaction (تراکنش توزیع‌شده)
* قدرت ویژگی اتمی‌بودن در تراکنش تخت، تا حدی ضعف آن هم هست.

**جزوه:**

* **Flat:** یک واحد یکپارچه، ساده‌ترین مدل.
* **Nested:** شکستن منطقی به زیرتراکنش‌ها برای کارایی/برنامه‌نویسی بهتر.
* **Distributed:** روی داده‌های توزیع‌شده اجرا می‌شود و هماهنگی سخت‌تری دارد.
* **نکته اسلاید:** atomicity خیلی سخت‌گیرانه در flat می‌تواند انعطاف را کم کند.

**تعاریف/توضیحات کوتاه:**

* **Nested:** تراکنش والد + چند فرزند (subtransactions).

**Key Points:**

* سه نوع اصلی: flat / nested / distributed.
* atomicity قوی همیشه هزینه دارد.

---

## **اسلاید 41 – عنوان: Nested transaction (تراکنش تو‌در‌تو)**
**ترجمه:**

* یک تراکنش تو‌در‌تو از چند **زیرتراکنش (sub transactions)** ساخته می‌شود.
* تراکنش سطح بالا می‌تواند فرزندهایی را ایجاد کند که موازی با هم، روی ماشین‌های مختلف اجرا شوند تا کارایی بالا رود یا برنامه‌نویسی ساده‌تر شود.
* اگر تراکنش دربرگیرنده (سطح بالاتر) Abort شود، همه‌ی زیرتراکنش‌های زیرمجموعه هم باید Abort شوند.

**جزوه:**

* **مزیت:** اجرای موازی زیرکارها ⇒ performance.
* **قاعده برگشت:** Abort والد ⇒ Abort همه فرزندان (وابستگی سلسله‌مراتبی).

**تعاریف/توضیحات کوتاه:**

* **Subtransaction:** بخش کوچک‌تری از کار که زیر نظر تراکنش والد اجرا می‌شود.

**Key Points:**

* Nested = hierarchy + parallel children.
* Abort والد همه را لغو می‌کند.

---

## **اسلاید 42 – عنوان: Distributed transaction (تراکنش توزیع‌شده)**
**ترجمه:**

* تراکنش تو‌در‌تو: تراکنشی که از نظر منطقی به یک سلسله‌مراتب از زیرتراکنش‌ها تجزیه می‌شود.
* تراکنش توزیع‌شده: از نظر منطقی یک تراکنش تخت و غیرقابل‌تقسیم است که روی داده‌های توزیع‌شده کار می‌کند.
* مشکل اصلی تراکنش‌های توزیع‌شده این است که برای **قفل‌گذاری (locking)** داده و **Commit کردن کل تراکنش**، به الگوریتم‌های توزیع‌شده جداگانه نیاز است.

**جزوه:**

* **فرق کلیدی:**

  * Nested: تقسیم داخلی به subtransactions
  * Distributed: واحد منطقی یکپارچه، اما داده/اجرا پخش‌شده
* **دو چالش بزرگ:**

  * distributed locking (قفل‌گذاری روی داده‌های پراکنده)
  * distributed commit (متعهدسازی هماهنگ)

**تعاریف/توضیحات کوتاه:**

* **Distributed Commit:** همه گره‌ها باید یا Commit کنند یا Abort؛ نیمه‌کاره قابل قبول نیست.

**Key Points:**

* distributed transaction = flat اما روی data توزیع‌شده.
* قفل‌گذاری و commit در توزیع‌شده سخت‌تر و نیازمند الگوریتم‌های ویژه است.

---

## **اسلاید 43 – عنوان: Distributed transaction – Fig 20 (شکل ۲۰)**
**ترجمه:**

* **شکل ۲۰: تراکنش توزیع‌شده (Distributed transaction)**

**جزوه:**

* **توضیح تصویر (کلی):**

  * معمولاً این شکل ارتباط بین **Transaction Manager**ها/گره‌ها و منابع داده‌ی مختلف را نشان می‌دهد که باید در یک تراکنش واحد هماهنگ شوند (برای commit/abort هماهنگ).

**تعاریف/توضیحات کوتاه:**

* شکل برای درک «پخش بودن داده/عملیات» در یک تراکنش واحد است.

**Key Points:**

* تصویر = نمایش اجزای درگیر در تراکنش توزیع‌شده و نیاز به هماهنگی.

---

## **اسلاید 44 – عنوان: Concurrency control (کنترل همروندی)**
**ترجمه:**

* هدف کنترل همروندی این است که چند تراکنش بتوانند هم‌زمان اجرا شوند، اما طوری که مجموعه داده‌هایی که دستکاری می‌شوند در یک حالت **سازگار (consistent)** باقی بمانند.
* کنترل همروندی را بهتر است با سه «مدیر/Manager» مختلف فهمید که به‌صورت لایه‌ای سازمان‌دهی می‌شوند.
* Concurrency control

**جزوه:**

* **مسئله:** اجرای همزمان ⇒ تداخل/ناهماهنگی محتمل.
* **هدف:** بیشترین همزمانی + حفظ سازگاری داده.

**تعاریف/توضیحات کوتاه:**

* **Concurrency Control:** سیاست‌ها/الگوریتم‌هایی برای جلوگیری از خطاهای ناشی از اجرای همزمان (مثل lost update).

**Key Points:**

* همزمانی مجاز است، اما با تضمین consistency.
* مدل لایه‌ای با 3 manager معرفی می‌شود.

---

## **اسلاید 45 – عنوان: Concurrency control – Layers (لایه‌ها)**
**ترجمه:**

1. لایه پایین: **Data Manager (مدیر داده)** که عملیات واقعی READ/WRITE را انجام می‌دهد.
2. لایه میانی: **Scheduler (زمان‌بند)** که مسئول اصلی کنترل درست است؛ تعیین می‌کند کدام تراکنش چه زمانی اجازه دارد عملیات خواندن/نوشتن را به Data Manager بدهد.
3. لایه بالا: **Transaction Manager (مدیر تراکنش)** که عمدتاً مسئول تضمین **Atomicity (اتمی‌بودن)** تراکنش‌هاست.

**جزوه:**

* **Data Manager:** اجراکننده‌ی واقعی عملیات روی داده.
* **Scheduler:** مغز کنترل همزمانی (اجازه/تاخیر).
* **Transaction Manager:** تضمین همه/هیچ و مدیریت commit/abort.

**تعاریف/توضیحات کوتاه:**

* **Scheduler:** همان بخشی که معمولاً lockها و تعارض‌ها را مدیریت می‌کند.

**Key Points:**

* 3 لایه: Data Manager / Scheduler / Transaction Manager.
* Scheduler تعیین می‌کند چه عملیاتی کی عبور کند.

---

## **اسلاید 46 – عنوان: Concurrency control – Fig 23 (شکل ۲۳)**
**ترجمه:**

* **شکل ۲۳: کنترل همروندی (Concurrency control)**

**جزوه:**

* **توضیح تصویر:**

  * معمولاً این شکل جریان درخواست‌های تراکنش از Transaction Manager به Scheduler و سپس به Data Manager را لایه‌به‌لایه نشان می‌دهد.

**تعاریف/توضیحات کوتاه:**

* تصویر برای جا افتادن معماری لایه‌ای کنترل همروندی است.

**Key Points:**

* شکل = نمایش نقش هر لایه در مسیر READ/WRITE.

---

## **اسلاید 47 – عنوان: Two-phase locking (قفل‌گذاری دو مرحله‌ای – 2PL)**
**ترجمه:**

* قدیمی‌ترین و پرکاربردترین الگوریتم کنترل همروندی، **Locking (قفل‌گذاری)** است.
* وقتی یک فرآیند باید به‌عنوان بخشی از تراکنش یک قلم داده را بخواند/بنویسد، از Scheduler می‌خواهد برای آن قلم داده یک **lock** بدهد.
* Scheduler باید الگوریتم **Two-Phase Locking (2PL)** را اعمال کند.
* در 2PL، Scheduler ابتدا در **Growing phase (فاز رشد)** همه lockهای لازم را می‌گیرد، و سپس در **Shrinking phase (فاز کاهش)** آن‌ها را آزاد می‌کند.

**جزوه:**

* **هدف 2PL:** جلوگیری از تداخل تراکنش‌ها با قواعد گرفتن/آزادکردن lock.
* **دو فاز:**

  * Growing: فقط lock گرفتن (release نداریم)
  * Shrinking: فقط release (lock جدید ممنوع)

**تعاریف/توضیحات کوتاه:**

* **2PL:** قانون «اول همه قفل‌ها را بگیر، بعد شروع به آزادسازی کن».

**Key Points:**

* Locking رایج‌ترین روش کنترل همروندی است.
* 2PL = Growing (acquire) + Shrinking (release).

---

## **اسلاید 48 – عنوان: Two-phase locking – Rules (قواعد 2PL)**
**ترجمه:**

1. وقتی Scheduler یک عملیات oper(T.x) را از Transaction Manager می‌گیرد، بررسی می‌کند آیا با عملیات دیگری که قبلاً برایش lock داده تعارض دارد یا نه. اگر تعارض بود، oper(T.x) به تأخیر می‌افتد (و در نتیجه خود تراکنش T هم). اگر تعارض نبود، Scheduler برای x lock می‌دهد و عملیات را به Data Manager می‌فرستد.
2. Scheduler هیچ lockی برای x را آزاد نمی‌کند تا وقتی Data Manager تأیید کند عملیاتی که lock برایش گرفته شده انجام شده است.
3. وقتی Scheduler یک lock را به نمایندگی از تراکنش T آزاد کرد، دیگر هرگز lock دیگری به نمایندگی از T نمی‌دهد (فرقی ندارد برای چه داده‌ای). تلاش T برای گرفتن lock جدید یک خطای برنامه‌نویسی است و باعث Abort شدن T می‌شود.

**جزوه:**

* **Rule 1:** تعارض ⇒ delay؛ بدون تعارض ⇒ grant lock و اجرا.
* **Rule 2:** release بعد از انجام واقعی عملیات (ack).
* **Rule 3 (جوهر 2PL):** بعد از اولین release، گرفتن lock جدید ممنوع.

**تعاریف/توضیحات کوتاه:**

* **Conflict (تعارض):** مثل خواندن/نوشتن همزمان روی یک داده که ناسازگار می‌شود.

**Key Points:**

* 2PL با «ممنوعیت lock جدید پس از release» تعریف می‌شود.
* Scheduler نقطه کنترل تعارض‌هاست.

---

## **اسلاید 49 – عنوان: Two-phase locking – Fig 26 (شکل ۲۶)**
**ترجمه:**

* **شکل ۲۶: قفل‌گذاری دو مرحله‌ای (Two-phase locking)**

**جزوه:**

* **توضیح تصویر:**

  * معمولاً نموداری است که محور زمان دارد و نشان می‌دهد:

    * در Growing phase تعداد lockها افزایش می‌یابد.
    * سپس در Shrinking phase lockها آزاد می‌شوند و دیگر lock جدید گرفته نمی‌شود.

**تعاریف/توضیحات کوتاه:**

* شکل برای تجسم «دو فاز بودن» lockهاست.

**Key Points:**

* Growing = acquire-only
* Shrinking = release-only

---

## **اسلاید 50 – عنوان: Two-phase locking – Strict 2PL (۲PL سخت‌گیرانه)**
**ترجمه:**

* این سیاست که **Strict two-phase locking (قفل‌گذاری دو مرحله‌ای سخت‌گیرانه)** نام دارد، دو مزیت اصلی دارد:

  1. یک تراکنش همیشه مقداری را می‌خوانَد که توسط یک تراکنش **commit‌شده** نوشته شده؛ بنابراین هیچ‌وقت لازم نیست یک تراکنش را Abort کنیم.
  2. گرفتن و آزاد کردن lockها می‌تواند توسط سیستم مدیریت شود، بدون اینکه تراکنش از آن‌ها آگاه باشد.
* lockها هر وقت قرار است به یک قلم داده دسترسی شود گرفته می‌شوند و وقتی تراکنش تمام شد آزاد می‌شوند.
* فاز Shrinking تا وقتی تراکنش تمام نشود رخ نمی‌دهد؛ تراکنش یا commit می‌شود یا abort، و سپس lockها آزاد می‌شوند.

**جزوه:**

* **Strict 2PL:** نگه‌داشتن lockها تا پایان تراکنش (commit/abort).
* **مزیت کلیدی:** جلوگیری از **cascading aborts** (اینجا با عبارت «نیازی به abort کردن نیست» اشاره شده: یعنی از خواندن داده‌ی تراکنشِ commit‌نشده جلوگیری می‌شود).
* **سیستم‌محور بودن:** برنامه‌نویس کمتر درگیر جزئیات lock.

**تعاریف/توضیحات کوتاه:**

* **Strict 2PL:** نسخه‌ای از 2PL که release اصلی lockها را تا پایان تراکنش عقب می‌اندازد تا خواندن داده‌ی ناتمام رخ ندهد.

**Key Points:**

* Strict 2PL خواندن داده‌ی commit‌نشده را حذف می‌کند.
* lockها تا پایان تراکنش نگه داشته می‌شوند.

---

## **اسلاید 51 – عنوان: Strict two-phase locking – Fig 27 (شکل ۲۷)**
**ترجمه:**

* **شکل ۲۷: Two-phase locking** (در زمینه Strict 2PL)

**جزوه:**

* **توضیح تصویر:**

  * معمولاً نشان می‌دهد که در Strict 2PL آزادسازی lockها به انتهای تراکنش منتقل می‌شود (یعنی shrinking عملاً در انتها اتفاق می‌افتد).

**تعاریف/توضیحات کوتاه:**

* تصویر برای مقایسه‌ی 2PL معمولی و Strict 2PL (از نظر زمان release) کاربرد دارد.

**Key Points:**

* در Strict 2PL، releaseها تا پایان تراکنش عقب می‌افتند.

---

## **اسلاید 52 – عنوان: Two-phase locking – Deadlocks (بن‌بست)**
**ترجمه:**

* هم 2PL و هم Strict 2PL می‌توانند باعث **Deadlock (بن‌بست)** شوند.
* تکنیک‌های معمول قابل استفاده‌اند؛ مثل گرفتن همه lockها در یک **ترتیب استاندارد (canonical order)** برای جلوگیری از چرخه‌های hold-and-wait.
* همچنین می‌شود بن‌بست را تشخیص داد: با نگه‌داشتن یک **گراف صریح (explicit graph)** از اینکه کدام فرآیند چه lockهایی دارد و چه lockهایی می‌خواهد.
* اگر از قبل بدانیم lock هیچ‌وقت بیشتر از t ثانیه نگه داشته نمی‌شود، می‌توان از **timeout** استفاده کرد: اگر یک lock بیشتر از t ثانیه دست یک مالک بماند، باید deadlock رخ داده باشد.

**جزوه:**

* **ریشه مشکل:** lockها می‌توانند چرخه انتظار ایجاد کنند.
* **راهکارها:**

  * **Prevention:** canonical order (همه یک ترتیب ثابت برای قفل‌ها)
  * **Detection:** wait-for / lock graph و پیدا کردن cycle
  * **Timeout:** اگر بیش از t طول کشید ⇒ احتمال deadlock

**تعاریف/توضیحات کوتاه:**

* **Deadlock:** چند تراکنش هر کدام منتظر lock دیگری‌اند و هیچ‌کدام جلو نمی‌رود.

**Key Points:**

* 2PL ممکن است deadlock بسازد.
* سه رویکرد: prevention / detection / timeout.

---

## **اسلاید 53 – عنوان: Two-phase locking – Distributed 2PL (۲PL توزیع‌شده)**
**ترجمه:**

* طرح پایه‌ی 2PL می‌تواند در یک سیستم توزیع‌شده پیاده‌سازی شود.
* Transaction Manager با یک **Centralized Lock Manager (مدیر قفل متمرکز)** ارتباط برقرار می‌کند و مجوز lock را از او می‌گیرد.
* وقتی lock داده شد، Transaction Manager بعداً مستقیم با Data Managerها ارتباط می‌گیرد.
* در 2PL توزیع‌شده (distributed 2PL) فرض می‌شود داده‌ها ممکن است در چند ماشین **replicate (تکثیر/کپی)** شده باشند.

**جزوه:**

* **معماری رایج:**

  * Locking متمرکز (برای ساده‌سازی تصمیم lock)
  * اجرای داده‌ای توزیع‌شده (دسترسی مستقیم به data managers)
* **چالش replication:** قفل‌گذاری باید با کپی‌های متعدد هم سازگار باشد.

**تعاریف/توضیحات کوتاه:**

* **Lock Manager:** سرویس/مولفه‌ای که تصمیم می‌گیرد چه کسی lock را بگیرد.
* **Replication:** وجود چند نسخه از یک داده روی چند گره.

**Key Points:**

* قفل‌ها از Centralized Lock Manager گرفته می‌شوند.
* بعد از grant، ارتباط با data managers مستقیم است.
* replication پیچیدگی 2PL را بیشتر می‌کند.

---

## **اسلاید 54 – عنوان: End of Chapter 5 (پایان فصل ۵)**
**ترجمه:**

* پایان فصل ۵

**جزوه:**

* جمع‌بندی مباحث این بخش از فصل:

  * الگوریتم‌های دسترسی به منبع مشترک (متمرکز/توزیع‌شده/Token Ring)
  * مدل تراکنش و ACID
  * کنترل همروندی و 2PL / Strict 2PL و مسئله deadlock
  * اشاره به 2PL در سیستم‌های توزیع‌شده و replication

**تعاریف/توضیحات کوتاه:**

* —

**Key Points:**

* پایان فصل ۵.
